name: Maven Build for Release

# Reusable workflow for building HDFView with Maven
# Replaces the legacy ant.yml and ant-app.yml workflows
# Downloads HDF4 and HDF5 libraries from HDF Group GitHub releases
on:
  workflow_call:
    inputs:
      file_base:
        description: 'Base name for artifacts'
        type: string
        required: true
      build_type:
        description: 'Build type: release or snapshot'
        type: string
        required: false
        default: 'snapshot'
      use_hdf:
        description: 'HDF4 release tag (e.g., snapshot, hdf4-1.2.3)'
        type: string
        required: false
        default: 'snapshot'
      use_hdf_name:
        description: 'HDF4 base filename (optional, uses wildcard if empty)'
        type: string
        required: false
        default: ''
      use_hdf5:
        description: 'HDF5 release tag (e.g., snapshot, hdf5-2.0.0)'
        type: string
        required: false
        default: 'snapshot'
      use_hdf5_name:
        description: 'HDF5 base filename (optional, uses wildcard if empty)'
        type: string
        required: false
        default: ''
      use_environ:
        description: 'Environment (snapshots or release)'
        type: string
        required: false
        default: 'snapshots'
      publish_to_maven_registry:
        description: 'Publish artifacts to GitHub Packages Maven registry'
        type: boolean
        required: false
        default: false

permissions:
  contents: read
  packages: write

env:
  MAVEN_OPTS: >-
    -Xmx2g
    -Xms1g
    -XX:+UseParallelGC
    -XX:+TieredCompilation
    -XX:TieredStopAtLevel=1
    -Djava.awt.headless=true
  # Prefix for HDF5 release file patterns: "" for snapshot, "hdf5-" for tagged releases
  # TODO: This is a hack to deal with the fact that HDF5 provides this part itself for snapshots,
  # but releases are just the version number.
  # HDF4 provides the prefix for snapshots and releases, so HDF4 does not need a corresponding variable.
  HDF5_PREFIX: ${{ (inputs.build_type == 'release' && 'hdf5-') || '' }}

jobs:
  build-linux:
    name: Build Linux Binary
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.use_hdf }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf_name }}" ]; then
          PATTERN="${{ inputs.use_hdf_name }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF4 binary from HDF Group GitHub releases
        gh release download "${{ inputs.use_hdf }}" \
          --repo HDFGroup/hdf4 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf4/ directory)
        tar -zxvf *-ubuntu-2404_gcc.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4

        # Extract inner tar.gz into hdf4/ directory
        cd "${{ github.workspace }}/hdf4"
        tar -zxvf HDF-*-Linux.tar.gz --strip-components 1

        # Set HDF4 library path
        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME_HDF=$(ls ${{ github.workspace }}/hdf4/HDF_Group/HDF)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME_HDF" >> $GITHUB_ENV

        echo "HDF4 installed to: $HDF4DIR$FILE_NAME_HDF"
        ls -la "$HDF4DIR$FILE_NAME_HDF"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.use_hdf5 }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf5_name }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.use_hdf5_name }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="hdf5-*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF5 binary from HDF Group GitHub releases
        gh release download "${{ inputs.use_hdf5 }}" \
          --repo HDFGroup/hdf5 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf5/ directory)
        tar -zxvf hdf5-*-ubuntu-2404_gcc.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5

        # Extract inner tar.gz into hdf5/ directory
        cd "${{ github.workspace }}/hdf5"
        tar -zxvf HDF5-*-Linux.tar.gz --strip-components 1

        # Set HDF5 library path
        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME_HDF5=$(ls ${{ github.workspace }}/hdf5/HDF_Group/HDF5)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME_HDF5" >> $GITHUB_ENV

        echo "HDF5 installed to: $HDF5DIR$FILE_NAME_HDF5"
        ls -la "$HDF5DIR$FILE_NAME_HDF5"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties << EOF
        # Build Properties using HDF libraries from GitHub releases
        # HDF4: ${{ inputs.use_hdf }}
        # HDF5: ${{ inputs.use_hdf5 }}
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

        echo "Generated build.properties:"
        cat build.properties

    - name: Install HDF JARs to Local Maven Repository
      run: |
        echo "Manually installing HDF JARs to avoid PMD issues..."

        # Copy HDF JARs from downloaded distributions to repository/lib
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs found"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs found"

        # List what we have
        echo "JARs in repository/lib:"
        ls -la repository/lib/*.jar

        # Manually install each JAR to local Maven repository
        # This bypasses the repository module's POM and avoids PMD issues

        # Install jarhdf5 (extract version from filename)
        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi

        # Install jarhdf (extract version from filename)
        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi

        # Install fits
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: fits.jar"
        else
          echo "ERROR: fits.jar not found in repository/lib/"
          exit 1
        fi

        # Install netcdf
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: netcdf.jar"
        else
          echo "ERROR: netcdf.jar not found in repository/lib/"
          exit 1
        fi

    - name: Build with Maven
      run: |
        echo "Building HDFView with Maven..."
        # Now build with package (HDF JARs already installed manually above)
        # Use -Dmaven.test.skip=true to skip test compilation entirely (module-info conflicts)
        # package phase stops before verify, avoiding PMD/Checkstyle execution
        mvn clean package -Dmaven.test.skip=true -Dhdf5.version="$HDF5_VERSION" -Dhdf.version="$HDF4_VERSION" -B

    - name: Create Linux Binary Archive
      run: |
        # Create a distribution directory
        mkdir -p hdfview-dist

        # Copy JAR files
        cp hdfview/target/*.jar hdfview-dist/ 2>/dev/null || echo "No hdfview JARs found"
        cp object/target/*.jar hdfview-dist/ 2>/dev/null || echo "No object JARs found"
        cp libs/*.jar hdfview-dist/ 2>/dev/null || echo "No libs JARs found"

        # Copy dependencies
        if [ -d "target/lib" ]; then
          cp -r target/lib hdfview-dist/
        fi

        # Copy HDF native libraries
        if [ -d "${{ env.HDF5LIB_PATH }}/lib" ]; then
          mkdir -p hdfview-dist/lib
          cp -L ${{ env.HDF5LIB_PATH }}/lib/*.so* hdfview-dist/lib/ 2>/dev/null || echo "No HDF5 .so files"
        fi
        if [ -d "${{ env.HDF4LIB_PATH }}/lib" ]; then
          mkdir -p hdfview-dist/lib
          cp -L ${{ env.HDF4LIB_PATH }}/lib/*.so* hdfview-dist/lib/ 2>/dev/null || echo "No HDF4 .so files"
        fi

        # Create archive with the expected naming convention
        tar -czf ${{ inputs.file_base }}-Linux-x86_64.tar.gz hdfview-dist/

        echo "Linux binary archive created: ${{ inputs.file_base }}-Linux-x86_64.tar.gz"
        ls -lh ${{ inputs.file_base }}-Linux-x86_64.tar.gz

    - name: Upload Linux Binary Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-ubuntu-2404-binary
        path: ${{ inputs.file_base }}-Linux-x86_64.tar.gz
        retention-days: 30

  build-linux-app:
    name: Build Linux Application Package
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.use_hdf }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf_name }}" ]; then
          PATTERN="${{ inputs.use_hdf_name }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF4 binary from HDF Group GitHub releases
        gh release download "${{ inputs.use_hdf }}" \
          --repo HDFGroup/hdf4 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf4/ directory)
        tar -zxvf *-ubuntu-2404_gcc.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4

        # Extract inner tar.gz into hdf4/ directory
        cd "${{ github.workspace }}/hdf4"
        tar -zxvf HDF-*-Linux.tar.gz --strip-components 1

        # Set HDF4 library path
        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME_HDF=$(ls ${{ github.workspace }}/hdf4/HDF_Group/HDF)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME_HDF" >> $GITHUB_ENV

        echo "HDF4 installed to: $HDF4DIR$FILE_NAME_HDF"
        ls -la "$HDF4DIR$FILE_NAME_HDF"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.use_hdf5 }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf5_name }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.use_hdf5_name }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="hdf5-*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF5 binary from HDF Group GitHub releases
        gh release download "${{ inputs.use_hdf5 }}" \
          --repo HDFGroup/hdf5 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf5/ directory)
        tar -zxvf hdf5-*-ubuntu-2404_gcc.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5

        # Extract inner tar.gz into hdf5/ directory
        cd "${{ github.workspace }}/hdf5"
        tar -zxvf HDF5-*-Linux.tar.gz --strip-components 1

        # Set HDF5 library path
        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME_HDF5=$(ls ${{ github.workspace }}/hdf5/HDF_Group/HDF5)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME_HDF5" >> $GITHUB_ENV

        echo "HDF5 installed to: $HDF5DIR$FILE_NAME_HDF5"
        ls -la "$HDF5DIR$FILE_NAME_HDF5"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties << EOF
        # Build Properties using HDF libraries from GitHub releases
        # HDF4: ${{ inputs.use_hdf }}
        # HDF5: ${{ inputs.use_hdf5 }}
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

        echo "Generated build.properties:"
        cat build.properties

    - name: Install HDF JARs to Local Maven Repository
      run: |
        echo "Manually installing HDF JARs to avoid PMD issues..."

        # Copy HDF JARs from downloaded distributions to repository/lib
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs found"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs found"

        # List what we have
        echo "JARs in repository/lib:"
        ls -la repository/lib/*.jar

        # Manually install each JAR to local Maven repository
        # This bypasses the repository module's POM and avoids PMD issues

        # Install jarhdf5 (extract version from filename)
        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi

        # Install jarhdf (extract version from filename)
        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi

        # Install fits
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: fits.jar"
        else
          echo "ERROR: fits.jar not found in repository/lib/"
          exit 1
        fi

        # Install netcdf
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: netcdf.jar"
        else
          echo "ERROR: netcdf.jar not found in repository/lib/"
          exit 1
        fi

    - name: Build and Package Application
      run: |
        echo "Building HDFView with Maven..."
        # Install parent POM first (required for child module resolution)
        mvn install -B -N -Ddependency-check.skip=true

        # Install object and hdfview modules (needed for jpackage)
        mvn install -B -pl object,hdfview -DskipTests -Ddependency-check.skip=true

        # Package application
        mvn package -DskipTests -B

    - name: Create jpackage App Image
      run: |
        echo "Creating distributable application package with jpackage..."

        # Create app-image using jpackage profile
        # -pl object,hdfview: Build object and hdfview modules (skip repository)
        # -Dmaven.test.skip=true: Skip test compilation and execution
        # -Djacoco.skip=true: Skip JaCoCo (not needed for release builds)
        # -Dpmd.skip=true: Skip PMD (static analysis not needed for release)
        # -Ddependency-check.skip=true: Skip OWASP (runs in separate security workflow)
        mvn verify -Pjpackage-app-image -pl object,hdfview \
          -Dmaven.test.skip=true \
          -Djacoco.skip=true \
          -Dpmd.skip=true \
          -Ddependency-check.skip=true \
          -B

        echo "Verifying jpackage output..."
        if [ -d hdfview/target/dist/HDFView ]; then
          echo "✓ jpackage app-image created successfully"
          echo "Package size: $(du -sh hdfview/target/dist/HDFView | cut -f1)"
          echo "Native libraries: $(find hdfview/target/dist/HDFView/lib/app -name "*.so" 2>/dev/null | wc -l) .so files"
          echo "JAR files: $(find hdfview/target/dist/HDFView/lib/app -name "*.jar" 2>/dev/null | wc -l) JARs"
          echo "HDF5 plugins: $(ls -1 hdfview/target/dist/HDFView/lib/app/plugin/*.so 2>/dev/null | wc -l) plugins"
        else
          echo "✗ jpackage app-image creation failed"
          exit 1
        fi

    - name: Create Linux Application Archive
      run: |
        # Package the jpackage app-image as a tar.gz for distribution
        cd hdfview/target/dist
        tar -czf ${{ github.workspace }}/${{ inputs.file_base }}App-Linux-x86_64.tar.gz HDFView/

        echo "Linux application archive created: ${{ inputs.file_base }}App-Linux-x86_64.tar.gz"
        ls -lh ${{ github.workspace }}/${{ inputs.file_base }}App-Linux-x86_64.tar.gz

    - name: Upload Linux App Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-ubuntu-2404-app-binary
        path: ${{ inputs.file_base }}App-Linux-x86_64.tar.gz
        retention-days: 30

  build-windows:
    name: Build Windows Binary
    runs-on: windows-latest
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF4 from release tag: ${{ inputs.use_hdf }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.use_hdf_name }}") {
          $PATTERN = "${{ inputs.use_hdf_name }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf }}" `
          --repo HDFGroup/hdf4 `
          --pattern $PATTERN `
          --clobber

        Write-Host "Extracting HDF4..."
        7z x *-win-vs2022_cl.zip
        # Rename hdf4-* directory to hdf4 if needed
        $hdf4Dir = Get-ChildItem -Directory -Filter "hdf4*" | Select-Object -First 1
        if ($hdf4Dir.Name -ne "hdf4") {
          Rename-Item $hdf4Dir.FullName "hdf4"
        }
        Set-Location hdf4
        7z x HDF-*-win64.zip

        # Windows structure: hdf4/HDF-4.3.1-win64/lib, hdf4/HDF-4.3.1-win64/bin
        # Find the extracted HDF-*-win64 directory
        $HDF4DIR = Get-ChildItem -Path . -Filter "HDF-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF4DIR) {
          Write-Error "HDF-*-win64 directory not found!"
          Get-ChildItem -Directory | ForEach-Object { Write-Host $_.Name }
          exit 1
        }
        $HDF4LIB_PATH = $HDF4DIR.FullName
        echo "HDF4LIB_PATH=$HDF4LIB_PATH" >> $env:GITHUB_ENV
        Write-Host "HDF4 installed to: $HDF4LIB_PATH"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF5 from release tag: ${{ inputs.use_hdf5 }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.use_hdf5_name }}") {
          $PATTERN = "${{ env.HDF5_PREFIX }}${{ inputs.use_hdf5_name }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "hdf5-*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf5 }}" `
          --repo HDFGroup/hdf5 `
          --pattern $PATTERN `
          --clobber

        Write-Host "Extracting HDF5..."
        7z x hdf5-*-win-vs2022_cl.zip
        # Rename hdf5-* directory to hdf5 if needed
        $hdf5Dir = Get-ChildItem -Directory -Filter "hdf5*" | Select-Object -First 1
        if ($hdf5Dir.Name -ne "hdf5") {
          Rename-Item $hdf5Dir.FullName "hdf5"
        }
        Set-Location hdf5
        7z x HDF5-*-win64.zip

        # Windows structure: hdf5/HDF5-x.y.z-win64/lib, hdf5/HDF5-x.y.z-win64/bin
        # Find the extracted HDF5-*-win64 directory
        $HDF5DIR = Get-ChildItem -Path . -Filter "HDF5-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF5DIR) {
          Write-Error "HDF5-*-win64 directory not found!"
          Get-ChildItem -Directory | ForEach-Object { Write-Host $_.Name }
          exit 1
        }
        $HDF5LIB_PATH = $HDF5DIR.FullName
        echo "HDF5LIB_PATH=$HDF5LIB_PATH" >> $env:GITHUB_ENV
        Write-Host "HDF5 installed to: $HDF5LIB_PATH"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      shell: pwsh
      run: |
        # Convert Windows paths to use forward slashes (Java/Maven compatible)
        $HDF5_PATH = $env:HDF5LIB_PATH -replace '\\', '/'
        $HDF4_PATH = $env:HDF4LIB_PATH -replace '\\', '/'

        @"
        hdf5.lib.dir=$HDF5_PATH/lib
        hdf5.plugin.dir=$HDF5_PATH/lib/plugin
        hdf.lib.dir=$HDF4_PATH/lib
        platform.hdf.lib=$HDF5_PATH/bin;$HDF4_PATH/bin
        "@ | Out-File -FilePath build.properties -Encoding utf8

        Write-Host "Generated build.properties:"
        Get-Content build.properties

    - name: Install HDF JARs to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing HDF JARs to local Maven repository..."
        New-Item -Path "repository\lib" -ItemType Directory -Force | Out-Null

        if (Test-Path "$env:HDF4LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF4LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "$env:HDF5LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF5LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\fits.jar") {
          Copy-Item "lib\fits.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\netcdf.jar") {
          Copy-Item "lib\netcdf.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }

        $jarhdf5 = Get-ChildItem "repository\lib\jarhdf5-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf5) {
          $HDF5_VERSION = $jarhdf5.Name -replace 'jarhdf5-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf5.FullName)" `
            "-DgroupId=jarhdf5" "-DartifactId=jarhdf5" "-Dversion=$HDF5_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf5.Name) as version $HDF5_VERSION"
          "HDF5_VERSION=$HDF5_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }

        $jarhdf = Get-ChildItem "repository\lib\jarhdf-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf) {
          $HDF4_VERSION = $jarhdf.Name -replace 'jarhdf-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf.FullName)" `
            "-DgroupId=jarhdf" "-DartifactId=jarhdf" "-Dversion=$HDF4_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf.Name) as version $HDF4_VERSION"
          "HDF4_VERSION=$HDF4_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }

        if (Test-Path "repository\lib\fits.jar") {
          mvn install:install-file "-Dfile=repository\lib\fits.jar" `
            "-DgroupId=fits" "-DartifactId=fits" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }

        if (Test-Path "repository\lib\netcdf.jar") {
          mvn install:install-file "-Dfile=repository\lib\netcdf.jar" `
            "-DgroupId=netcdf" "-DartifactId=netcdf" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }

    - name: Build repository module (copies platform SWT JAR)
      shell: pwsh
      run: |
        Write-Host "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing Windows SWT JAR to local Maven repository..."
        if (Test-Path "repository\lib\swt.jar") {
          mvn install:install-file "-Dfile=repository\lib\swt.jar" `
            "-DgroupId=org.eclipse.platform" `
            "-DartifactId=org.eclipse.swt.win32.win32.amd64" `
            "-Dversion=3.126.0" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "Windows SWT JAR installed"
        } else {
          Write-Error "swt.jar not found in repository/lib/"
          exit 1
        }

    - name: Install SWTBot JARs to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing SWTBot JARs to local Maven repository..."

        if (Test-Path "repository\lib\org.eclipse.swtbot.swt.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.swt.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.swt.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot SWT finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        }

        if (Test-Path "repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.nebula.nattable.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot Nebula NatTable finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        }

    - name: Build with Maven
      shell: pwsh
      run: |
        Write-Host "Building HDFView with Maven..."
        # Build object and hdfview modules, stop at package phase to avoid verify/PMD
        mvn package -pl object,hdfview "-Dmaven.test.skip=true" "-Dhdf5.version=$env:HDF5_VERSION" "-Dhdf.version=$env:HDF4_VERSION" -B

    - name: Create Windows Binary Archive
      shell: pwsh
      run: |
        New-Item -Path "hdfview-dist" -ItemType Directory -Force

        # Copy JARs
        Copy-Item "libs\*.jar" -Destination "hdfview-dist\"
        Copy-Item "hdfview\target\*.jar" -Destination "hdfview-dist\" -ErrorAction SilentlyContinue
        Copy-Item "object\target\*.jar" -Destination "hdfview-dist\" -ErrorAction SilentlyContinue

        # Create lib directory and copy DLLs
        New-Item -Path "hdfview-dist\lib" -ItemType Directory -Force
        Copy-Item "$env:HDF4LIB_PATH\bin\*.dll" -Destination "hdfview-dist\lib\" -ErrorAction SilentlyContinue
        Copy-Item "$env:HDF5LIB_PATH\bin\*.dll" -Destination "hdfview-dist\lib\" -ErrorAction SilentlyContinue

        # Create ZIP archive
        Compress-Archive -Path "hdfview-dist\*" -DestinationPath "${{ inputs.file_base }}-win64.zip"

    - name: Upload Windows Binary Artifact
      uses: actions/upload-artifact@v4
      with:
        name: zip-win-vs2022-binary
        path: ${{ inputs.file_base }}-win64.zip
        retention-days: 30

  build-windows-app:
    name: Build Windows Application Package
    runs-on: windows-latest
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF4 from release tag: ${{ inputs.use_hdf }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.use_hdf_name }}") {
          $PATTERN = "${{ inputs.use_hdf_name }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf }}" --repo HDFGroup/hdf4 --pattern $PATTERN --clobber
        7z x *-win-vs2022_cl.zip
        # Rename hdf4-* directory to hdf4 if needed
        $hdf4Dir = Get-ChildItem -Directory -Filter "hdf4*" | Select-Object -First 1
        if ($hdf4Dir.Name -ne "hdf4") {
          Rename-Item $hdf4Dir.FullName "hdf4"
        }
        Set-Location hdf4
        7z x HDF-*-win64.zip
        # Windows structure: hdf4/HDF-4.3.1-win64/lib, hdf4/HDF-4.3.1-win64/bin
        $HDF4DIR = Get-ChildItem -Path . -Filter "HDF-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF4DIR) {
          Write-Error "HDF-*-win64 directory not found!"
          exit 1
        }
        echo "HDF4LIB_PATH=$($HDF4DIR.FullName)" >> $env:GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF5 from release tag: ${{ inputs.use_hdf5 }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.use_hdf5_name }}") {
          $PATTERN = "${{ env.HDF5_PREFIX }}${{ inputs.use_hdf5_name }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "hdf5-*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf5 }}" --repo HDFGroup/hdf5 --pattern $PATTERN --clobber
        7z x hdf5-*-win-vs2022_cl.zip
        # Rename hdf5-* directory to hdf5 if needed
        $hdf5Dir = Get-ChildItem -Directory -Filter "hdf5*" | Select-Object -First 1
        if ($hdf5Dir.Name -ne "hdf5") {
          Rename-Item $hdf5Dir.FullName "hdf5"
        }
        Set-Location hdf5
        7z x HDF5-*-win64.zip
        # Windows structure: hdf5/HDF5-x.y.z-win64/lib, hdf5/HDF5-x.y.z-win64/bin
        $HDF5DIR = Get-ChildItem -Path . -Filter "HDF5-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF5DIR) {
          Write-Error "HDF5-*-win64 directory not found!"
          exit 1
        }
        echo "HDF5LIB_PATH=$($HDF5DIR.FullName)" >> $env:GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      shell: pwsh
      run: |
        # Convert Windows paths to use forward slashes (Java/Maven compatible)
        $HDF5_PATH = $env:HDF5LIB_PATH -replace '\\', '/'
        $HDF4_PATH = $env:HDF4LIB_PATH -replace '\\', '/'

        @"
        hdf5.lib.dir=$HDF5_PATH/lib
        hdf5.plugin.dir=$HDF5_PATH/lib/plugin
        hdf.lib.dir=$HDF4_PATH/lib
        platform.hdf.lib=$HDF5_PATH/bin;$HDF4_PATH/bin
        "@ | Out-File -FilePath build.properties -Encoding utf8

        Write-Host "Generated build.properties:"
        Get-Content build.properties

    - name: Install HDF JARs to Local Maven Repository
      shell: pwsh
      run: |
        New-Item -Path "repository\lib" -ItemType Directory -Force | Out-Null
        if (Test-Path "$env:HDF4LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF4LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "$env:HDF5LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF5LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\fits.jar") {
          Copy-Item "lib\fits.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\netcdf.jar") {
          Copy-Item "lib\netcdf.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        $jarhdf5 = Get-ChildItem "repository\lib\jarhdf5-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf5) {
          $HDF5_VERSION = $jarhdf5.Name -replace 'jarhdf5-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf5.FullName)" `
            "-DgroupId=jarhdf5" "-DartifactId=jarhdf5" "-Dversion=$HDF5_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf5.Name) as version $HDF5_VERSION"
          "HDF5_VERSION=$HDF5_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }
        $jarhdf = Get-ChildItem "repository\lib\jarhdf-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf) {
          $HDF4_VERSION = $jarhdf.Name -replace 'jarhdf-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf.FullName)" `
            "-DgroupId=jarhdf" "-DartifactId=jarhdf" "-Dversion=$HDF4_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf.Name) as version $HDF4_VERSION"
          "HDF4_VERSION=$HDF4_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }
        if (Test-Path "repository\lib\fits.jar") {
          mvn install:install-file "-Dfile=repository\lib\fits.jar" `
            "-DgroupId=fits" "-DartifactId=fits" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }
        if (Test-Path "repository\lib\netcdf.jar") {
          mvn install:install-file "-Dfile=repository\lib\netcdf.jar" `
            "-DgroupId=netcdf" "-DartifactId=netcdf" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }

    - name: Build repository module (copies platform SWT JAR)
      shell: pwsh
      run: |
        Write-Host "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing Windows SWT JAR to local Maven repository..."
        if (Test-Path "repository\lib\swt.jar") {
          mvn install:install-file "-Dfile=repository\lib\swt.jar" `
            "-DgroupId=org.eclipse.platform" `
            "-DartifactId=org.eclipse.swt.win32.win32.amd64" `
            "-Dversion=3.126.0" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "Windows SWT JAR installed"
        } else {
          Write-Error "swt.jar not found in repository/lib/"
          exit 1
        }

    - name: Install SWTBot JARs to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing SWTBot JARs to local Maven repository..."

        if (Test-Path "repository\lib\org.eclipse.swtbot.swt.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.swt.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.swt.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot SWT finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        }

        if (Test-Path "repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.nebula.nattable.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot Nebula NatTable finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        }

    - name: Build and Package Application
      shell: pwsh
      run: |
        Write-Host "Building HDFView with Maven..."
        # Install parent POM first (required for child module resolution)
        mvn install -B -N "-Ddependency-check.skip=true"

        # Install object and hdfview modules (needed for jpackage)
        mvn install -B -pl object,hdfview -DskipTests "-Ddependency-check.skip=true"

        # Package application
        mvn package -DskipTests -B

    - name: Create jpackage App Image
      shell: pwsh
      run: |
        Write-Host "Creating distributable application package with jpackage..."

        # Create app-image using jpackage profile
        # -pl object,hdfview: Build object and hdfview modules (skip repository)
        # -Dmaven.test.skip=true: Skip test compilation and execution
        # -Djacoco.skip=true: Skip JaCoCo (not needed for release builds)
        # -Dpmd.skip=true: Skip PMD (static analysis not needed for release)
        # -Ddependency-check.skip=true: Skip OWASP (runs in separate security workflow)
        mvn verify -Pjpackage-app-image -pl object,hdfview `
          "-Dmaven.test.skip=true" `
          "-Djacoco.skip=true" `
          "-Dpmd.skip=true" `
          "-Ddependency-check.skip=true" `
          -B

        Write-Host "Verifying jpackage output..."
        if (Test-Path "hdfview\target\dist\HDFView") {
          Write-Host "✓ jpackage app-image created successfully"
          $size = (Get-ChildItem -Recurse "hdfview\target\dist\HDFView" | Measure-Object -Property Length -Sum).Sum / 1MB
          Write-Host "Package size: $([math]::Round($size, 2)) MB"
          $dlls = (Get-ChildItem -Recurse "hdfview\target\dist\HDFView\lib\app\*.dll" -ErrorAction SilentlyContinue).Count
          Write-Host "Native libraries: $dlls .dll files"
          $jars = (Get-ChildItem -Recurse "hdfview\target\dist\HDFView\lib\app\*.jar" -ErrorAction SilentlyContinue).Count
          Write-Host "JAR files: $jars JARs"
        } else {
          Write-Error "✗ jpackage app-image creation failed"
          exit 1
        }

    - name: Create Windows Application Archive
      shell: pwsh
      run: |
        # Package the jpackage app-image as a ZIP for distribution
        # Note: Must preserve HDFView directory structure for jpackage --app-image to work
        Set-Location "hdfview\target\dist"
        Compress-Archive -Path "HDFView" -DestinationPath "${{ github.workspace }}\${{ inputs.file_base }}App-win64.zip"

        Write-Host "Windows application archive created: ${{ inputs.file_base }}App-win64.zip"
        Get-Item "${{ github.workspace }}\${{ inputs.file_base }}App-win64.zip" | Select-Object Name, Length

    - name: Upload Windows App Artifact
      uses: actions/upload-artifact@v4
      with:
        name: zip-win-vs2022-app-binary
        path: ${{ inputs.file_base }}App-win64.zip
        retention-days: 30

  build-macos:
    name: Build macOS Binary
    runs-on: macos-latest
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.use_hdf }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf_name }}" ]; then
          PATTERN="${{ inputs.use_hdf_name }}-macos14_clang.tar.gz"
        else
          PATTERN="*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf }}" \
          --repo HDFGroup/hdf4 \
          --pattern "$PATTERN" \
          --clobber

        echo "Extracting HDF4..."
        tar -zxvf *-macos14_clang.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4
        cd hdf4
        tar -zxvf HDF-*-Darwin.tar.gz --strip-components 1

        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME=$(ls $HDF4DIR)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME" >> $GITHUB_ENV
        echo "HDF4 installed to: $HDF4DIR$FILE_NAME"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.use_hdf5 }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf5_name }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.use_hdf5_name }}-macos14_clang.tar.gz"
        else
          PATTERN="hdf5-*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf5 }}" \
          --repo HDFGroup/hdf5 \
          --pattern "$PATTERN" \
          --clobber

        echo "Extracting HDF5..."
        tar -zxvf hdf5-*-macos14_clang.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5
        cd hdf5
        tar -zxvf HDF5-*-Darwin.tar.gz --strip-components 1

        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME=$(ls $HDF5DIR)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME" >> $GITHUB_ENV
        echo "HDF5 installed to: $HDF5DIR$FILE_NAME"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties <<EOF
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

        echo "Generated build.properties:"
        cat build.properties

    - name: Install HDF JARs to Local Maven Repository
      run: |
        echo "Installing HDF JARs to local Maven repository..."
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs"
        cp lib/fits.jar repository/lib/ 2>/dev/null || echo "fits.jar not found"
        cp lib/netcdf.jar repository/lib/ 2>/dev/null || echo "netcdf.jar not found"

        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi

        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi

        # Install fits
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: fits.jar"
        else
          echo "ERROR: fits.jar not found in repository/lib/"
          exit 1
        fi

        # Install netcdf
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: netcdf.jar"
        else
          echo "ERROR: netcdf.jar not found in repository/lib/"
          exit 1
        fi

    - name: Build repository module (copies platform SWT JAR)
      run: |
        echo "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      run: |
        echo "Installing macOS SWT JAR to local Maven repository..."
        if [ -f repository/lib/swt.jar ]; then
          mvn install:install-file -Dfile=repository/lib/swt.jar \
            -DgroupId=org.eclipse.platform \
            -DartifactId=org.eclipse.swt.cocoa.macosx.amd64 \
            -Dversion=3.126.0 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "macOS SWT JAR installed"
        else
          echo "ERROR: swt.jar not found in repository/lib/"
          exit 1
        fi

    - name: Install SWTBot JARs to Local Maven Repository
      run: |
        echo "Installing SWTBot JARs to local Maven repository..."

        if [ -f repository/lib/org.eclipse.swtbot.swt.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.swt.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.swt.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot SWT finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        fi

        if [ -f repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.nebula.nattable.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot Nebula NatTable finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        fi

    - name: Build with Maven
      run: |
        echo "Building HDFView with Maven..."
        # Build object and hdfview modules, stop at package phase to avoid verify/PMD
        mvn package -pl object,hdfview -Dmaven.test.skip=true -Dhdf5.version="$HDF5_VERSION" -Dhdf.version="$HDF4_VERSION" -B

    - name: Create macOS Binary Archive
      run: |
        mkdir -p hdfview-dist

        # Copy JARs
        cp libs/*.jar hdfview-dist/
        cp hdfview/target/*.jar hdfview-dist/ 2>/dev/null || true
        cp object/target/*.jar hdfview-dist/ 2>/dev/null || true

        # Create lib directory and copy dylibs
        mkdir -p hdfview-dist/lib
        cp -L ${{ env.HDF4LIB_PATH }}/lib/*.dylib hdfview-dist/lib/ 2>/dev/null || true
        cp -L ${{ env.HDF5LIB_PATH }}/lib/*.dylib hdfview-dist/lib/ 2>/dev/null || true

        # Create tar.gz archive
        tar -czf ${{ inputs.file_base }}-Darwin.tar.gz -C hdfview-dist .

    - name: Upload macOS Binary Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-macos14_clang-binary
        path: ${{ inputs.file_base }}-Darwin.tar.gz
        retention-days: 30

  build-macos-app:
    name: Build macOS Application Package
    runs-on: macos-latest
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.use_hdf }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf_name }}" ]; then
          PATTERN="${{ inputs.use_hdf_name }}-macos14_clang.tar.gz"
        else
          PATTERN="*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf }}" --repo HDFGroup/hdf4 --pattern "$PATTERN" \
          --clobber
        tar -zxvf *-macos14_clang.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4
        cd hdf4
        tar -zxvf HDF-*-Darwin.tar.gz --strip-components 1
        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME=$(ls $HDF4DIR)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME" >> $GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.use_hdf5 }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf5_name }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.use_hdf5_name }}-macos14_clang.tar.gz"
        else
          PATTERN="hdf5-*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.use_hdf5 }}" --repo HDFGroup/hdf5 --pattern "$PATTERN" \
          --clobber
        tar -zxvf hdf5-*-macos14_clang.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5
        cd hdf5
        tar -zxvf HDF5-*-Darwin.tar.gz --strip-components 1
        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME=$(ls $HDF5DIR)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME" >> $GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties <<EOF
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

    - name: Install HDF JARs to Local Maven Repository
      run: |
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs"
        cp lib/fits.jar repository/lib/ 2>/dev/null || echo "fits.jar not found"
        cp lib/netcdf.jar repository/lib/ 2>/dev/null || echo "netcdf.jar not found"
        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi
        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 -Dpackaging=jar -DgeneratePom=true
        fi
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 -Dpackaging=jar -DgeneratePom=true
        fi

    - name: Build repository module (copies platform SWT JAR)
      run: |
        echo "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      run: |
        echo "Installing macOS SWT JAR to local Maven repository..."
        if [ -f repository/lib/swt.jar ]; then
          mvn install:install-file -Dfile=repository/lib/swt.jar \
            -DgroupId=org.eclipse.platform \
            -DartifactId=org.eclipse.swt.cocoa.macosx.amd64 \
            -Dversion=3.126.0 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "macOS SWT JAR installed"
        else
          echo "ERROR: swt.jar not found in repository/lib/"
          exit 1
        fi

    - name: Install SWTBot JARs to Local Maven Repository
      run: |
        echo "Installing SWTBot JARs to local Maven repository..."

        if [ -f repository/lib/org.eclipse.swtbot.swt.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.swt.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.swt.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot SWT finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        fi

        if [ -f repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.nebula.nattable.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot Nebula NatTable finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        fi

    - name: Build and Package Application
      run: |
        echo "Building HDFView with Maven..."
        # Install parent POM first (required for child module resolution)
        mvn install -B -N -Ddependency-check.skip=true

        # Install object and hdfview modules (needed for jpackage)
        mvn install -B -pl object,hdfview -DskipTests -Ddependency-check.skip=true

        # Package application
        mvn package -DskipTests -B

    - name: Create jpackage App Image
      run: |
        echo "Creating distributable application package with jpackage..."

        # Create app-image using jpackage profile
        # -pl object,hdfview: Build object and hdfview modules (skip repository)
        # -Dmaven.test.skip=true: Skip test compilation and execution
        # -Djacoco.skip=true: Skip JaCoCo (not needed for release builds)
        # -Dpmd.skip=true: Skip PMD (static analysis not needed for release)
        # -Ddependency-check.skip=true: Skip OWASP (runs in separate security workflow)
        mvn verify -Pjpackage-app-image -pl object,hdfview \
          -Dmaven.test.skip=true \
          -Djacoco.skip=true \
          -Dpmd.skip=true \
          -Ddependency-check.skip=true \
          -B

        echo "Verifying jpackage output..."
        if [ -d hdfview/target/dist/HDFView.app ]; then
          echo "✓ jpackage app-image created successfully"
          echo "Package size: $(du -sh hdfview/target/dist/HDFView.app | cut -f1)"
          echo "Native libraries: $(find hdfview/target/dist/HDFView.app/Contents -name "*.dylib" 2>/dev/null | wc -l) .dylib files"
          echo "JAR files: $(find hdfview/target/dist/HDFView.app/Contents -name "*.jar" 2>/dev/null | wc -l) JARs"
          echo "HDF5 plugins: $(ls -1 hdfview/target/dist/HDFView.app/Contents/app/plugin/*.dylib 2>/dev/null | wc -l) plugins"
        else
          echo "✗ jpackage app-image creation failed"
          exit 1
        fi

    - name: Create macOS Application Archive
      run: |
        # Package the jpackage app-image as a tar.gz for distribution
        cd hdfview/target/dist
        tar -czf ${{ github.workspace }}/${{ inputs.file_base }}App-Darwin.tar.gz HDFView.app/

        echo "macOS application archive created: ${{ inputs.file_base }}App-Darwin.tar.gz"
        ls -lh ${{ github.workspace }}/${{ inputs.file_base }}App-Darwin.tar.gz

    - name: Upload macOS App Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-macos14_clang-app-binary
        path: ${{ inputs.file_base }}App-Darwin.tar.gz
        retention-days: 30

  build-linux-installers:
    name: Build Linux Installers (DEB/RPM)
    runs-on: ubuntu-latest
    needs: build-linux-app
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Download Linux App Artifact
      uses: actions/download-artifact@v4
      with:
        name: tgz-ubuntu-2404-app-binary

    - name: Extract App Image
      run: |
        tar -xzf ${{ inputs.file_base }}App-Linux-x86_64.tar.gz
        ls -la HDFView/

    - name: Create DEB Installer
      run: |
        echo "DEB installer creation - to be implemented"
        echo "Requires jpackage-deb profile and package files"
        # TODO: Implement DEB creation once jpackage profile is ready

    - name: Create RPM Installer
      run: |
        echo "RPM installer creation - to be implemented"
        echo "Requires jpackage-rpm profile and package files"
        # TODO: Implement RPM creation once jpackage profile is ready

  build-macos-installer:
    name: Build macOS Installer (DMG)
    runs-on: macos-latest
    needs: build-macos-app
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Download macOS App Artifact
      uses: actions/download-artifact@v4
      with:
        name: tgz-macos14_clang-app-binary

    - name: Extract App Image
      run: |
        tar -xzf ${{ inputs.file_base }}App-Darwin.tar.gz
        ls -la

    - name: Setup Keychain and Certificate
      if: github.repository == 'HDFGroup/hdfview' && env.MACOS_CERTIFICATE != ''
      env:
        MACOS_CERTIFICATE: ${{ secrets.MACOS_CERTIFICATE }}
        MACOS_CERT_PASSWORD: ${{ secrets.MACOS_CERT_PASSWORD }}
        MACOS_KEYCHAIN_PASSWORD: ${{ secrets.MACOS_KEYCHAIN_PASSWORD }}
      run: |
        echo "Setting up temporary keychain for code signing..."

        # Create temporary keychain
        security create-keychain -p "$MACOS_KEYCHAIN_PASSWORD" build.keychain
        security default-keychain -s build.keychain
        security unlock-keychain -p "$MACOS_KEYCHAIN_PASSWORD" build.keychain
        security set-keychain-settings build.keychain

        # Decode and import certificate
        echo "$MACOS_CERTIFICATE" | base64 --decode > certificate.p12
        security import certificate.p12 \
          -k build.keychain \
          -P "$MACOS_CERT_PASSWORD" \
          -T /usr/bin/codesign \
          -T /usr/bin/productsign

        # Allow codesign to access keychain
        security set-key-partition-list -S apple-tool:,apple: \
          -k "$MACOS_KEYCHAIN_PASSWORD" \
          build.keychain

        # Clean up certificate file
        rm certificate.p12

        echo "Keychain setup complete"

    - name: Sign App Bundle
      if: github.repository == 'HDFGroup/hdfview' && env.MACOS_CERTIFICATE != ''
      env:
        MACOS_DEVELOPER_ID: ${{ secrets.MACOS_DEVELOPER_ID }}
      run: |
        echo "Code signing app bundle..."

        # Sign the app bundle
        codesign --force --timestamp --options runtime \
          --entitlements lib/macosx/distribution.entitlements \
          --verbose=4 --strict \
          --sign "$MACOS_DEVELOPER_ID" \
          --deep \
          HDFView.app

        # Verify signature
        codesign -dvv HDFView.app
        codesign -vvvv --strict HDFView.app

        echo "App bundle signed successfully"

    - name: Create DMG Installer
      run: |
        echo "Creating DMG installer from app-image..."

        # Use jpackage to create DMG from app-image
        jpackage \
          --type dmg \
          --app-image HDFView.app \
          --name HDFView \
          --app-version 3.4.0 \
          --mac-package-identifier HDFView.hdfgroup.org \
          --mac-package-name HDFView-3.4.0 \
          --file-associations package_files/HDFViewHDF.properties \
          --file-associations package_files/HDFViewH4.properties \
          --file-associations package_files/HDFViewHDF4.properties \
          --file-associations package_files/HDFViewH5.properties \
          --file-associations package_files/HDFViewHDF5.properties \
          --dest .

        echo "DMG installer created successfully"
        ls -lh *.dmg

    - name: Sign DMG Installer
      if: github.repository == 'HDFGroup/hdfview' && env.MACOS_CERTIFICATE != ''
      env:
        MACOS_DEVELOPER_ID: ${{ secrets.MACOS_DEVELOPER_ID }}
      run: |
        echo "Code signing DMG installer..."

        # Sign the DMG
        codesign --force --timestamp --options runtime \
          --entitlements lib/macosx/distribution.entitlements \
          --verbose=4 --strict \
          --sign "$MACOS_DEVELOPER_ID" \
          --deep \
          HDFView-3.4.0.dmg

        # Verify signature
        codesign -dvv HDFView-3.4.0.dmg

        # Verify DMG integrity
        hdiutil verify HDFView-3.4.0.dmg

        echo "DMG installer signed successfully"

    - name: Notarize DMG
      if: github.repository == 'HDFGroup/hdfview' && env.MACOS_CERTIFICATE != ''
      env:
        APPLE_ID: ${{ secrets.APPLE_ID }}
        APPLE_ID_PASSWORD: ${{ secrets.APPLE_ID_PASSWORD }}
        APPLE_TEAM_ID: ${{ secrets.APPLE_TEAM_ID }}
      run: |
        echo "Submitting DMG for notarization..."

        # Submit for notarization and wait for completion
        xcrun notarytool submit \
          --wait \
          --output-format json \
          --apple-id "$APPLE_ID" \
          --password "$APPLE_ID_PASSWORD" \
          --team-id "$APPLE_TEAM_ID" \
          HDFView-3.4.0.dmg > notarization-output.json

        # Check if notarization succeeded
        STATUS=$(jq -r '.status' notarization-output.json)
        if [ "$STATUS" != "Accepted" ]; then
          echo "Notarization failed with status: $STATUS"
          jq '.' notarization-output.json
          exit 1
        fi

        echo "Notarization completed successfully"

    - name: Staple Notarization Ticket
      if: github.repository == 'HDFGroup/hdfview' && env.MACOS_CERTIFICATE != ''
      run: |
        echo "Stapling notarization ticket to DMG..."

        # Staple the notarization ticket
        xcrun stapler staple HDFView-3.4.0.dmg

        # Validate stapling
        xcrun stapler validate -v HDFView-3.4.0.dmg

        # Verify with spctl
        spctl -vvvv --assess --type install HDFView-3.4.0.dmg || true

        echo "Notarization ticket stapled successfully"

    - name: Cleanup Keychain
      if: always() && github.repository == 'HDFGroup/hdfview' && env.MACOS_CERTIFICATE != ''
      run: |
        security delete-keychain build.keychain || true

    - name: Upload macOS DMG Installer
      uses: actions/upload-artifact@v4
      with:
        name: HDFView-3.4.0-macOS-dmg
        path: HDFView-3.4.0.dmg
        retention-days: 5

  build-windows-installer:
    name: Build Windows Installer (MSI)
    runs-on: windows-latest
    needs: build-windows-app
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Download Windows App Artifact
      uses: actions/download-artifact@v4
      with:
        name: zip-win-vs2022-app-binary

    - name: Extract App Image
      shell: pwsh
      run: |
        Expand-Archive -Path "${{ inputs.file_base }}App-win64.zip" -DestinationPath .
        Get-ChildItem -Recurse

    - name: Create MSI Installer
      shell: pwsh
      run: |
        Write-Host "Creating MSI installer from app-image..."

        # Use jpackage to create MSI from app-image
        jpackage `
          --type msi `
          --app-image HDFView `
          --name HDFView `
          --app-version 3.4.0 `
          --icon package_files\hdfview.ico `
          --win-dir-chooser `
          --win-per-user-install `
          --win-menu `
          --win-menu-group "The HDF Group" `
          --file-associations package_files\HDFViewHDF.properties `
          --file-associations package_files\HDFViewH4.properties `
          --file-associations package_files\HDFViewHDF4.properties `
          --file-associations package_files\HDFViewH5.properties `
          --file-associations package_files\HDFViewHDF5.properties `
          --dest .

        Write-Host "MSI installer created successfully"
        Get-ChildItem *.msi

    - name: Sign MSI Installer
      if: github.repository == 'HDFGroup/hdfview' && env.WINDOWS_CERTIFICATE != ''
      shell: pwsh
      env:
        WINDOWS_CERTIFICATE: ${{ secrets.WINDOWS_CERTIFICATE }}
        WINDOWS_CERT_PASSWORD: ${{ secrets.WINDOWS_CERT_PASSWORD }}
      run: |
        Write-Host "Signing MSI installer..."

        # Decode certificate from base64
        $certBytes = [System.Convert]::FromBase64String($env:WINDOWS_CERTIFICATE)
        $certPath = Join-Path $env:TEMP "cert.pfx"
        [System.IO.File]::WriteAllBytes($certPath, $certBytes)

        # Find signtool.exe
        $signtool = Get-ChildItem -Path "${env:ProgramFiles(x86)}\Windows Kits\10\bin" -Recurse -Filter "signtool.exe" |
          Where-Object { $_.FullName -match "x64" } |
          Select-Object -First 1

        if (-not $signtool) {
          Write-Error "signtool.exe not found"
          exit 1
        }

        Write-Host "Using signtool: $($signtool.FullName)"

        # Sign the MSI
        & $signtool.FullName sign `
          /v `
          /debug `
          /fd SHA256 `
          /d "HDFView 3.4.0 Installer" `
          /f $certPath `
          /p $env:WINDOWS_CERT_PASSWORD `
          /t http://timestamp.digicert.com `
          HDFView-3.4.0.msi

        if ($LASTEXITCODE -ne 0) {
          Write-Error "Signing failed with exit code $LASTEXITCODE"
          exit $LASTEXITCODE
        }

        # Verify signature
        & $signtool.FullName verify /pa /v HDFView-3.4.0.msi

        # Clean up certificate
        Remove-Item $certPath

        Write-Host "MSI installer signed successfully"

    - name: Upload Windows MSI Installer
      uses: actions/upload-artifact@v4
      with:
        name: HDFView-3.4.0-win64-msi
        path: HDFView-3.4.0.msi
        retention-days: 5

  publish-packages:
    name: Publish Maven Packages
    runs-on: ubuntu-latest
    if: inputs.publish_to_maven_registry == true
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: ~/.m2/repository
        key: ${{ runner.os }}-maven-publish-${{ hashFiles('**/pom.xml') }}

    - name: Install HDF Libraries
      run: |
        sudo apt-get update
        sudo apt-get install -y libhdf5-dev libhdf4-dev

        # Try to install Java packages if available (may not exist in all Ubuntu versions)
        sudo apt-get install -y libhdf5-java || echo "libhdf5-java not available, will use GitHub releases"
        sudo apt-get install -y libhdf4-java || echo "libhdf4-java not available, will use GitHub releases"

    - name: Install Java Dependencies to Maven Local Repository
      run: |
        echo "Installing Java dependencies..."

        # Install fits.jar and netcdf.jar from repository
        mvn install:install-file -Dfile=repository/lib/fits.jar \
          -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
          -Dpackaging=jar -DgeneratePom=true

        mvn install:install-file -Dfile=repository/lib/netcdf.jar \
          -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
          -Dpackaging=jar -DgeneratePom=true

        # Install HDF JARs - try system packages first, fallback to downloading
        # Note: libhdf4-java and libhdf5-java may not be available in all Ubuntu versions
        echo "Checking for HDF Java packages..."

        # Always download jarhdf5 from GitHub (system packages are outdated)
        echo "Downloading jarhdf5.jar from GitHub release: ${{ inputs.use_hdf5 }}..."

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.use_hdf5_name }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.use_hdf5_name }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="*ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        mkdir -p /tmp/hdf5-download && cd /tmp/hdf5-download
          gh release download "${{ inputs.use_hdf5 }}" --repo HDFGroup/hdf5 --pattern "$PATTERN"
          tar -zxf hdf5-*-ubuntu-2404_gcc.tar.gz
          cd hdf5

          # Extract inner tar.gz
          HDF5_TARBALL=$(ls HDF5-*-Linux.tar.gz | head -1)
          tar -zxf "$HDF5_TARBALL" --strip-components 1

          # Find JAR in HDF_Group/HDF5/version/lib structure
          if [ -d HDF_Group/HDF5 ]; then
            VERSION_DIR=$(ls HDF_Group/HDF5 | head -1)
            JAR_FILE=$(ls HDF_Group/HDF5/$VERSION_DIR/lib/jarhdf5*.jar 2>/dev/null | head -1)
            if [ -f "$JAR_FILE" ]; then
              HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
              mvn install:install-file -Dfile="$JAR_FILE" \
                -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" \
                -Dpackaging=jar -DgeneratePom=true
              echo "Installed jarhdf5.jar from GitHub: $JAR_FILE as version $HDF5_VERSION"
              echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
            fi
          fi
          cd ${{ github.workspace }}

        # Try jarhdf from system packages, fallback to GitHub download
        if [ -f /usr/share/java/jarhdf.jar ]; then
          echo "Installing jarhdf.jar from system packages"
          # Extract version from jar if possible, otherwise use default
          JAR_PATH="/usr/share/java/jarhdf.jar"
          # System jarhdf.jar typically doesn't have version in filename, check actual file
          if jar -tf "$JAR_PATH" | grep -q "MANIFEST.MF"; then
            HDF4_VERSION=$(unzip -p "$JAR_PATH" META-INF/MANIFEST.MF | grep "Implementation-Version" | cut -d' ' -f2 | tr -d '\r' || echo "4.3.1")
          else
            HDF4_VERSION="4.3.1"
          fi
          mvn install:install-file -Dfile="$JAR_PATH" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed jarhdf.jar from system packages as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        else
          echo "System packages don't provide jarhdf.jar, downloading from GitHub release: ${{ inputs.use_hdf }}..."

          # Determine file pattern based on whether base name is provided
          if [ -n "${{ inputs.use_hdf_name }}" ]; then
            PATTERN="${{ inputs.use_hdf_name }}-ubuntu-2404_gcc.tar.gz"
          else
            PATTERN="*ubuntu-2404_gcc.tar.gz"
          fi
          echo "Using pattern: $PATTERN"

          mkdir -p /tmp/hdf4-download && cd /tmp/hdf4-download
          gh release download "${{ inputs.use_hdf }}" --repo HDFGroup/hdf4 --pattern "$PATTERN"
          tar -zxf hdf4*-ubuntu-2404_gcc.tar.gz
          cd hdf4

          # Extract inner tar.gz
          HDF4_TARBALL=$(ls HDF-*-Linux.tar.gz | head -1)
          tar -zxf "$HDF4_TARBALL" --strip-components 1

          # Find JAR in HDF_Group/HDF/version/lib structure
          if [ -d HDF_Group/HDF ]; then
            VERSION_DIR=$(ls HDF_Group/HDF | head -1)
            JAR_FILE=$(ls HDF_Group/HDF/$VERSION_DIR/lib/jarhdf-*.jar 2>/dev/null | head -1)
            if [ -f "$JAR_FILE" ]; then
              HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
              mvn install:install-file -Dfile="$JAR_FILE" \
                -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
                -Dpackaging=jar -DgeneratePom=true
              echo "Installed jarhdf.jar from GitHub: $JAR_FILE as version $HDF4_VERSION"
              echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
            fi
          fi
          cd ${{ github.workspace }}
        fi

        # Install SWTBot JARs for UI testing
        mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.swt.finder.jar \
          -DgroupId=org.eclipse.local -DartifactId=org.eclipse.swtbot.swt.finder -Dversion=4.2.1 \
          -Dpackaging=jar -DgeneratePom=true

        mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar \
          -DgroupId=org.eclipse.local -DartifactId=org.eclipse.swtbot.nebula.nattable.finder -Dversion=4.2.1 \
          -Dpackaging=jar -DgeneratePom=true

        echo "All Java dependencies installed successfully"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties << EOF
        hdf5.lib.dir=/usr/lib/x86_64-linux-gnu
        hdf5.plugin.dir=/usr/lib/x86_64-linux-gnu/lib/plugin
        hdf.lib.dir=/usr/lib/x86_64-linux-gnu
        platform.hdf.lib=/usr/lib/x86_64-linux-gnu
        ci.build=true
        release.build=true
        EOF

    - name: Configure Maven Settings
      run: |
        mkdir -p ~/.m2
        cat > ~/.m2/settings.xml << EOF
        <settings>
          <servers>
            <server>
              <id>github</id>
              <username>\${env.GITHUB_ACTOR}</username>
              <password>\${env.GITHUB_TOKEN}</password>
            </server>
          </servers>
        </settings>
        EOF

    - name: Publish to GitHub Packages
      run: |
        mvn deploy -B \
          -pl object,hdfview \
          -DskipTests \
          -Ddependency-check.skip=true \
          -Dmaven.javadoc.skip=false \
          -Dmaven.source.skip=false \
          -Dhdf5.version="$HDF5_VERSION" \
          -Dhdf.version="$HDF4_VERSION" \
          -DaltDeploymentRepository=github::default::https://maven.pkg.github.com/${{ github.repository }}
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
