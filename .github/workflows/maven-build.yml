name: Maven Build for Release

# Reusable workflow for building HDFView with Maven
# Replaces the legacy ant.yml and ant-app.yml workflows
# Downloads HDF4 and HDF5 libraries from HDF Group GitHub releases
on:
  workflow_call:
    inputs:
      artifact_basename:
        description: 'Base name for all build artifacts (e.g., hdfview-master-abc1234 or HDFView-3.4.0)'
        type: string
        required: true
      build_type:
        description: 'Build type: release or snapshot'
        type: string
        required: false
        default: 'snapshot'
      hdf4_version_tag:
        description: 'HDF4 release tag (e.g., snapshot, hdf4-1.2.3)'
        type: string
        required: false
        default: 'snapshot'
      hdf4_artifact_basename:
        description: 'HDF4 base filename (optional, uses wildcard if empty)'
        type: string
        required: false
        default: ''
      hdf5_version_tag:
        description: 'HDF5 release tag (e.g., snapshot, hdf5-2.0.0)'
        type: string
        required: false
        default: 'snapshot'
      hdf5_artifact_basename:
        description: 'HDF5 base filename (optional, uses wildcard if empty)'
        type: string
        required: false
        default: ''
      build_environment:
        description: 'Environment (snapshots or release)'
        type: string
        required: false
        default: 'snapshots'
      publish_to_maven_registry:
        description: 'Publish artifacts to GitHub Packages Maven registry'
        type: boolean
        required: false
        default: false
    secrets:
      # macOS Code Signing
      APPLE_CERTS_BASE64:
        description: 'macOS Developer ID certificate (base64 encoded P12)'
        required: false
      APPLE_CERTS_BASE64_PASSWD:
        description: 'Password for macOS certificate'
        required: false
      KEYCHAIN_PASSWD:
        description: 'Password for temporary keychain'
        required: false
      # macOS Notarization
      APPLE_ID:
        description: 'Apple ID for notarization'
        required: false
      APPLE_ID_PASSWORD:
        description: 'App-specific password for Apple ID'
        required: false
      APPLE_TEAM_ID:
        description: 'Apple Developer Team ID'
        required: false
      # Windows Code Signing via Azure
      AZURE_TENANT_ID:
        description: 'Azure tenant ID for code signing'
        required: false
      AZURE_CLIENT_ID:
        description: 'Azure client ID for code signing'
        required: false
      AZURE_CLIENT_SECRET:
        description: 'Azure client secret for code signing'
        required: false
      AZURE_ENDPOINT:
        description: 'Azure Code Signing endpoint'
        required: false
      AZURE_CODE_SIGNING_NAME:
        description: 'Azure code signing account name'
        required: false
      AZURE_CERT_PROFILE_NAME:
        description: 'Azure certificate profile name'
        required: false

permissions:
  contents: read
  packages: write

env:
  MAVEN_OPTS: >-
    -Xmx2g
    -Xms1g
    -XX:+UseParallelGC
    -XX:+TieredCompilation
    -XX:TieredStopAtLevel=1
    -Djava.awt.headless=true
  # Prefix for HDF5 release file patterns: "" for snapshot, "hdf5-" for tagged releases
  # TODO: This is a hack to deal with the fact that HDF5 provides this part itself for snapshots,
  # but releases are just the version number.
  # HDF4 provides the prefix for snapshots and releases, so HDF4 does not need a corresponding variable.
  HDF5_PREFIX: ${{ (inputs.build_type == 'release' && 'hdf5-') || '' }}

jobs:
  build-linux:
    name: Build Linux Binary
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.hdf4_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf4_artifact_basename }}" ]; then
          PATTERN="${{ inputs.hdf4_artifact_basename }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF4 binary from HDF Group GitHub releases
        gh release download "${{ inputs.hdf4_version_tag }}" \
          --repo HDFGroup/hdf4 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf4/ directory)
        tar -zxvf *-ubuntu-2404_gcc.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4

        # Extract inner tar.gz into hdf4/ directory
        cd "${{ github.workspace }}/hdf4"
        tar -zxvf HDF-*-Linux.tar.gz --strip-components 1

        # Set HDF4 library path
        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME_HDF=$(ls ${{ github.workspace }}/hdf4/HDF_Group/HDF)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME_HDF" >> $GITHUB_ENV

        echo "HDF4 installed to: $HDF4DIR$FILE_NAME_HDF"
        ls -la "$HDF4DIR$FILE_NAME_HDF"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.hdf5_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf5_artifact_basename }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.hdf5_artifact_basename }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="hdf5-*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF5 binary from HDF Group GitHub releases
        gh release download "${{ inputs.hdf5_version_tag }}" \
          --repo HDFGroup/hdf5 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf5/ directory)
        tar -zxvf hdf5-*-ubuntu-2404_gcc.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5

        # Extract inner tar.gz into hdf5/ directory
        cd "${{ github.workspace }}/hdf5"
        tar -zxvf HDF5-*-Linux.tar.gz --strip-components 1

        # Set HDF5 library path
        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME_HDF5=$(ls ${{ github.workspace }}/hdf5/HDF_Group/HDF5)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME_HDF5" >> $GITHUB_ENV

        echo "HDF5 installed to: $HDF5DIR$FILE_NAME_HDF5"
        ls -la "$HDF5DIR$FILE_NAME_HDF5"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties << EOF
        # Build Properties using HDF libraries from GitHub releases
        # HDF4: ${{ inputs.hdf4_version_tag }}
        # HDF5: ${{ inputs.hdf5_version_tag }}
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

        echo "Generated build.properties:"
        cat build.properties

    - name: Install HDF JARs to Local Maven Repository
      run: |
        echo "Manually installing HDF JARs to avoid PMD issues..."

        # Copy HDF JARs from downloaded distributions to repository/lib
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs found"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs found"

        # List what we have
        echo "JARs in repository/lib:"
        ls -la repository/lib/*.jar

        # Manually install each JAR to local Maven repository
        # This bypasses the repository module's POM and avoids PMD issues

        # Install jarhdf5 (extract version from filename)
        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi

        # Install jarhdf (extract version from filename)
        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi

        # Install fits
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: fits.jar"
        else
          echo "ERROR: fits.jar not found in repository/lib/"
          exit 1
        fi

        # Install netcdf
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: netcdf.jar"
        else
          echo "ERROR: netcdf.jar not found in repository/lib/"
          exit 1
        fi

    - name: Install SWTBot JARs to Local Maven Repository
      run: |
        echo "Installing SWTBot JARs to local Maven repository..."

        if [ -f repository/lib/org.eclipse.swtbot.swt.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.swt.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.swt.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot SWT finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        fi

        if [ -f repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.nebula.nattable.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot Nebula NatTable finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        fi

    - name: Build with Maven
      run: |
        echo "Building HDFView with Maven..."
        # Now build with package (HDF JARs already installed manually above)
        # Use -Dmaven.test.skip=true to skip test compilation entirely (module-info conflicts)
        # package phase stops before verify, avoiding PMD/Checkstyle execution
        mvn clean package -Dmaven.test.skip=true -Dhdf5.version="$HDF5_VERSION" -Dhdf.version="$HDF4_VERSION" -B

    - name: Create Linux Binary Archive
      run: |
        # Create a distribution directory
        mkdir -p hdfview-dist

        # Copy JAR files
        cp hdfview/target/*.jar hdfview-dist/ 2>/dev/null || echo "No hdfview JARs found"
        cp object/target/*.jar hdfview-dist/ 2>/dev/null || echo "No object JARs found"
        cp libs/*.jar hdfview-dist/ 2>/dev/null || echo "No libs JARs found"

        # Copy dependencies
        if [ -d "target/lib" ]; then
          cp -r target/lib hdfview-dist/
        fi

        # Copy HDF native libraries
        if [ -d "${{ env.HDF5LIB_PATH }}/lib" ]; then
          mkdir -p hdfview-dist/lib
          cp -L ${{ env.HDF5LIB_PATH }}/lib/*.so* hdfview-dist/lib/ 2>/dev/null || echo "No HDF5 .so files"
        fi
        if [ -d "${{ env.HDF4LIB_PATH }}/lib" ]; then
          mkdir -p hdfview-dist/lib
          cp -L ${{ env.HDF4LIB_PATH }}/lib/*.so* hdfview-dist/lib/ 2>/dev/null || echo "No HDF4 .so files"
        fi

        # Create archive with the expected naming convention
        tar -czf ${{ inputs.artifact_basename }}-Linux-x86_64.tar.gz hdfview-dist/

        echo "Linux binary archive created: ${{ inputs.artifact_basename }}-Linux-x86_64.tar.gz"
        ls -lh ${{ inputs.artifact_basename }}-Linux-x86_64.tar.gz

    - name: Upload Linux Binary Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-ubuntu-2404-binary
        path: ${{ inputs.artifact_basename }}-Linux-x86_64.tar.gz
        retention-days: 30

  build-linux-app:
    name: Build Linux Application Package
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.hdf4_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf4_artifact_basename }}" ]; then
          PATTERN="${{ inputs.hdf4_artifact_basename }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF4 binary from HDF Group GitHub releases
        gh release download "${{ inputs.hdf4_version_tag }}" \
          --repo HDFGroup/hdf4 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf4/ directory)
        tar -zxvf *-ubuntu-2404_gcc.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4

        # Extract inner tar.gz into hdf4/ directory
        cd "${{ github.workspace }}/hdf4"
        tar -zxvf HDF-*-Linux.tar.gz --strip-components 1

        # Set HDF4 library path
        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME_HDF=$(ls ${{ github.workspace }}/hdf4/HDF_Group/HDF)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME_HDF" >> $GITHUB_ENV

        echo "HDF4 installed to: $HDF4DIR$FILE_NAME_HDF"
        ls -la "$HDF4DIR$FILE_NAME_HDF"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.hdf5_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf5_artifact_basename }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.hdf5_artifact_basename }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="hdf5-*-ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        # Download HDF5 binary from HDF Group GitHub releases
        gh release download "${{ inputs.hdf5_version_tag }}" \
          --repo HDFGroup/hdf5 \
          --pattern "$PATTERN" \
          --clobber

        # Extract outer tar.gz (creates hdf5/ directory)
        tar -zxvf hdf5-*-ubuntu-2404_gcc.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5

        # Extract inner tar.gz into hdf5/ directory
        cd "${{ github.workspace }}/hdf5"
        tar -zxvf HDF5-*-Linux.tar.gz --strip-components 1

        # Set HDF5 library path
        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME_HDF5=$(ls ${{ github.workspace }}/hdf5/HDF_Group/HDF5)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME_HDF5" >> $GITHUB_ENV

        echo "HDF5 installed to: $HDF5DIR$FILE_NAME_HDF5"
        ls -la "$HDF5DIR$FILE_NAME_HDF5"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties << EOF
        # Build Properties using HDF libraries from GitHub releases
        # HDF4: ${{ inputs.hdf4_version_tag }}
        # HDF5: ${{ inputs.hdf5_version_tag }}
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

        echo "Generated build.properties:"
        cat build.properties

    - name: Install HDF JARs to Local Maven Repository
      run: |
        echo "Manually installing HDF JARs to avoid PMD issues..."

        # Copy HDF JARs from downloaded distributions to repository/lib
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs found"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs found"

        # List what we have
        echo "JARs in repository/lib:"
        ls -la repository/lib/*.jar

        # Manually install each JAR to local Maven repository
        # This bypasses the repository module's POM and avoids PMD issues

        # Install jarhdf5 (extract version from filename)
        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi

        # Install jarhdf (extract version from filename)
        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi

        # Install fits
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: fits.jar"
        else
          echo "ERROR: fits.jar not found in repository/lib/"
          exit 1
        fi

        # Install netcdf
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: netcdf.jar"
        else
          echo "ERROR: netcdf.jar not found in repository/lib/"
          exit 1
        fi

    - name: Build and Package Application
      run: |
        echo "Building HDFView with Maven..."
        # Install parent POM first (required for child module resolution)
        mvn install -B -N -Ddependency-check.skip=true

        # Install object and hdfview modules (needed for jpackage)
        mvn install -B -pl object,hdfview -DskipTests -Ddependency-check.skip=true

        # Package application
        mvn package -DskipTests -B

    - name: Create jpackage App Image
      run: |
        echo "Creating distributable application package with jpackage..."

        # Create app-image using jpackage profile
        # -pl object,hdfview: Build object and hdfview modules (skip repository)
        # -Dmaven.test.skip=true: Skip test compilation and execution
        # -Djacoco.skip=true: Skip JaCoCo (not needed for release builds)
        # -Dpmd.skip=true: Skip PMD (static analysis not needed for release)
        # -Ddependency-check.skip=true: Skip OWASP (runs in separate security workflow)
        mvn verify -Pjpackage-app-image -pl object,hdfview \
          -Dmaven.test.skip=true \
          -Djacoco.skip=true \
          -Dpmd.skip=true \
          -Ddependency-check.skip=true \
          -B

        echo "Verifying jpackage output..."
        if [ -d hdfview/target/dist/HDFView ]; then
          echo "✓ jpackage app-image created successfully"
          echo "Package size: $(du -sh hdfview/target/dist/HDFView | cut -f1)"
          echo "Native libraries: $(find hdfview/target/dist/HDFView/lib/app -name "*.so" 2>/dev/null | wc -l) .so files"
          echo "JAR files: $(find hdfview/target/dist/HDFView/lib/app -name "*.jar" 2>/dev/null | wc -l) JARs"
          echo "HDF5 plugins: $(ls -1 hdfview/target/dist/HDFView/lib/app/plugin/*.so 2>/dev/null | wc -l) plugins"
        else
          echo "✗ jpackage app-image creation failed"
          exit 1
        fi

    - name: Create Linux Application Archive
      run: |
        # Package the jpackage app-image as a tar.gz for distribution
        cd hdfview/target/dist
        tar -czf ${{ github.workspace }}/${{ inputs.artifact_basename }}App-Linux-x86_64.tar.gz HDFView/

        echo "Linux application archive created: ${{ inputs.artifact_basename }}App-Linux-x86_64.tar.gz"
        ls -lh ${{ github.workspace }}/${{ inputs.artifact_basename }}App-Linux-x86_64.tar.gz

    - name: Upload Linux App Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-ubuntu-2404-app-binary
        path: ${{ inputs.artifact_basename }}App-Linux-x86_64.tar.gz
        retention-days: 30

  build-windows:
    name: Build Windows Binary
    runs-on: windows-latest
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF4 from release tag: ${{ inputs.hdf4_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.hdf4_artifact_basename }}") {
          $PATTERN = "${{ inputs.hdf4_artifact_basename }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf4_version_tag }}" `
          --repo HDFGroup/hdf4 `
          --pattern $PATTERN `
          --clobber

        Write-Host "Extracting HDF4..."
        7z x *-win-vs2022_cl.zip
        # Rename hdf4-* directory to hdf4 if needed
        $hdf4Dir = Get-ChildItem -Directory -Filter "hdf4*" | Select-Object -First 1
        if ($hdf4Dir.Name -ne "hdf4") {
          Rename-Item $hdf4Dir.FullName "hdf4"
        }
        Set-Location hdf4
        7z x HDF-*-win64.zip

        # Windows structure: hdf4/HDF-4.3.1-win64/lib, hdf4/HDF-4.3.1-win64/bin
        # Find the extracted HDF-*-win64 directory
        $HDF4DIR = Get-ChildItem -Path . -Filter "HDF-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF4DIR) {
          Write-Error "HDF-*-win64 directory not found!"
          Get-ChildItem -Directory | ForEach-Object { Write-Host $_.Name }
          exit 1
        }
        $HDF4LIB_PATH = $HDF4DIR.FullName
        echo "HDF4LIB_PATH=$HDF4LIB_PATH" >> $env:GITHUB_ENV
        Write-Host "HDF4 installed to: $HDF4LIB_PATH"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF5 from release tag: ${{ inputs.hdf5_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.hdf5_artifact_basename }}") {
          $PATTERN = "${{ env.HDF5_PREFIX }}${{ inputs.hdf5_artifact_basename }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "hdf5-*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf5_version_tag }}" `
          --repo HDFGroup/hdf5 `
          --pattern $PATTERN `
          --clobber

        Write-Host "Extracting HDF5..."
        7z x hdf5-*-win-vs2022_cl.zip
        # Rename hdf5-* directory to hdf5 if needed
        $hdf5Dir = Get-ChildItem -Directory -Filter "hdf5*" | Select-Object -First 1
        if ($hdf5Dir.Name -ne "hdf5") {
          Rename-Item $hdf5Dir.FullName "hdf5"
        }
        Set-Location hdf5
        7z x HDF5-*-win64.zip

        # Windows structure: hdf5/HDF5-x.y.z-win64/lib, hdf5/HDF5-x.y.z-win64/bin
        # Find the extracted HDF5-*-win64 directory
        $HDF5DIR = Get-ChildItem -Path . -Filter "HDF5-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF5DIR) {
          Write-Error "HDF5-*-win64 directory not found!"
          Get-ChildItem -Directory | ForEach-Object { Write-Host $_.Name }
          exit 1
        }
        $HDF5LIB_PATH = $HDF5DIR.FullName
        echo "HDF5LIB_PATH=$HDF5LIB_PATH" >> $env:GITHUB_ENV
        Write-Host "HDF5 installed to: $HDF5LIB_PATH"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      shell: pwsh
      run: |
        # Convert Windows paths to use forward slashes (Java/Maven compatible)
        $HDF5_PATH = $env:HDF5LIB_PATH -replace '\\', '/'
        $HDF4_PATH = $env:HDF4LIB_PATH -replace '\\', '/'

        @"
        hdf5.lib.dir=$HDF5_PATH/lib
        hdf5.plugin.dir=$HDF5_PATH/lib/plugin
        hdf.lib.dir=$HDF4_PATH/lib
        platform.hdf.lib=$HDF5_PATH/bin;$HDF4_PATH/bin
        "@ | Out-File -FilePath build.properties -Encoding utf8

        Write-Host "Generated build.properties:"
        Get-Content build.properties

    - name: Install HDF JARs to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing HDF JARs to local Maven repository..."
        New-Item -Path "repository\lib" -ItemType Directory -Force | Out-Null

        if (Test-Path "$env:HDF4LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF4LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "$env:HDF5LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF5LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\fits.jar") {
          Copy-Item "lib\fits.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\netcdf.jar") {
          Copy-Item "lib\netcdf.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }

        $jarhdf5 = Get-ChildItem "repository\lib\jarhdf5-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf5) {
          $HDF5_VERSION = $jarhdf5.Name -replace 'jarhdf5-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf5.FullName)" `
            "-DgroupId=jarhdf5" "-DartifactId=jarhdf5" "-Dversion=$HDF5_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf5.Name) as version $HDF5_VERSION"
          "HDF5_VERSION=$HDF5_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }

        $jarhdf = Get-ChildItem "repository\lib\jarhdf-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf) {
          $HDF4_VERSION = $jarhdf.Name -replace 'jarhdf-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf.FullName)" `
            "-DgroupId=jarhdf" "-DartifactId=jarhdf" "-Dversion=$HDF4_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf.Name) as version $HDF4_VERSION"
          "HDF4_VERSION=$HDF4_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }

        if (Test-Path "repository\lib\fits.jar") {
          mvn install:install-file "-Dfile=repository\lib\fits.jar" `
            "-DgroupId=fits" "-DartifactId=fits" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }

        if (Test-Path "repository\lib\netcdf.jar") {
          mvn install:install-file "-Dfile=repository\lib\netcdf.jar" `
            "-DgroupId=netcdf" "-DartifactId=netcdf" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }

    - name: Build repository module (copies platform SWT JAR)
      shell: pwsh
      run: |
        Write-Host "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing Windows SWT JAR to local Maven repository..."
        if (Test-Path "repository\lib\swt.jar") {
          mvn install:install-file "-Dfile=repository\lib\swt.jar" `
            "-DgroupId=org.eclipse.platform" `
            "-DartifactId=org.eclipse.swt.win32.win32.amd64" `
            "-Dversion=3.126.0" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "Windows SWT JAR installed"
        } else {
          Write-Error "swt.jar not found in repository/lib/"
          exit 1
        }

    - name: Install SWTBot JARs to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing SWTBot JARs to local Maven repository..."

        if (Test-Path "repository\lib\org.eclipse.swtbot.swt.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.swt.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.swt.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot SWT finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        }

        if (Test-Path "repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.nebula.nattable.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot Nebula NatTable finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        }

    - name: Build with Maven
      shell: pwsh
      run: |
        Write-Host "Building HDFView with Maven..."
        # Build object and hdfview modules, stop at package phase to avoid verify/PMD
        mvn package -pl object,hdfview "-Dmaven.test.skip=true" "-Dhdf5.version=$env:HDF5_VERSION" "-Dhdf.version=$env:HDF4_VERSION" -B

    - name: Create Windows Binary Archive
      shell: pwsh
      run: |
        New-Item -Path "hdfview-dist" -ItemType Directory -Force

        # Copy JARs
        Copy-Item "libs\*.jar" -Destination "hdfview-dist\"
        Copy-Item "hdfview\target\*.jar" -Destination "hdfview-dist\" -ErrorAction SilentlyContinue
        Copy-Item "object\target\*.jar" -Destination "hdfview-dist\" -ErrorAction SilentlyContinue

        # Create lib directory and copy DLLs
        New-Item -Path "hdfview-dist\lib" -ItemType Directory -Force
        Copy-Item "$env:HDF4LIB_PATH\bin\*.dll" -Destination "hdfview-dist\lib\" -ErrorAction SilentlyContinue
        Copy-Item "$env:HDF5LIB_PATH\bin\*.dll" -Destination "hdfview-dist\lib\" -ErrorAction SilentlyContinue

        # Create ZIP archive
        Compress-Archive -Path "hdfview-dist\*" -DestinationPath "${{ inputs.artifact_basename }}-win64.zip"

    - name: Upload Windows Binary Artifact
      uses: actions/upload-artifact@v4
      with:
        name: zip-win-vs2022-binary
        path: ${{ inputs.artifact_basename }}-win64.zip
        retention-days: 30

  build-windows-app:
    name: Build Windows Application Package
    runs-on: windows-latest
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF4 from release tag: ${{ inputs.hdf4_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.hdf4_artifact_basename }}") {
          $PATTERN = "${{ inputs.hdf4_artifact_basename }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf4_version_tag }}" --repo HDFGroup/hdf4 --pattern $PATTERN --clobber
        7z x *-win-vs2022_cl.zip
        # Rename hdf4-* directory to hdf4 if needed
        $hdf4Dir = Get-ChildItem -Directory -Filter "hdf4*" | Select-Object -First 1
        if ($hdf4Dir.Name -ne "hdf4") {
          Rename-Item $hdf4Dir.FullName "hdf4"
        }
        Set-Location hdf4
        7z x HDF-*-win64.zip
        # Windows structure: hdf4/HDF-4.3.1-win64/lib, hdf4/HDF-4.3.1-win64/bin
        $HDF4DIR = Get-ChildItem -Path . -Filter "HDF-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF4DIR) {
          Write-Error "HDF-*-win64 directory not found!"
          exit 1
        }
        echo "HDF4LIB_PATH=$($HDF4DIR.FullName)" >> $env:GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      shell: pwsh
      run: |
        Write-Host "Downloading HDF5 from release tag: ${{ inputs.hdf5_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if ("${{ inputs.hdf5_artifact_basename }}") {
          $PATTERN = "${{ env.HDF5_PREFIX }}${{ inputs.hdf5_artifact_basename }}-win-vs2022_cl.zip"
        } else {
          $PATTERN = "hdf5-*-win-vs2022_cl.zip"
        }
        Write-Host "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf5_version_tag }}" --repo HDFGroup/hdf5 --pattern $PATTERN --clobber
        7z x hdf5-*-win-vs2022_cl.zip
        # Rename hdf5-* directory to hdf5 if needed
        $hdf5Dir = Get-ChildItem -Directory -Filter "hdf5*" | Select-Object -First 1
        if ($hdf5Dir.Name -ne "hdf5") {
          Rename-Item $hdf5Dir.FullName "hdf5"
        }
        Set-Location hdf5
        7z x HDF5-*-win64.zip
        # Windows structure: hdf5/HDF5-x.y.z-win64/lib, hdf5/HDF5-x.y.z-win64/bin
        $HDF5DIR = Get-ChildItem -Path . -Filter "HDF5-*-win64" -Directory | Select-Object -First 1
        if (-not $HDF5DIR) {
          Write-Error "HDF5-*-win64 directory not found!"
          exit 1
        }
        echo "HDF5LIB_PATH=$($HDF5DIR.FullName)" >> $env:GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      shell: pwsh
      run: |
        # Convert Windows paths to use forward slashes (Java/Maven compatible)
        $HDF5_PATH = $env:HDF5LIB_PATH -replace '\\', '/'
        $HDF4_PATH = $env:HDF4LIB_PATH -replace '\\', '/'

        @"
        hdf5.lib.dir=$HDF5_PATH/lib
        hdf5.plugin.dir=$HDF5_PATH/lib/plugin
        hdf.lib.dir=$HDF4_PATH/lib
        platform.hdf.lib=$HDF5_PATH/bin;$HDF4_PATH/bin
        "@ | Out-File -FilePath build.properties -Encoding utf8

        Write-Host "Generated build.properties:"
        Get-Content build.properties

    - name: Install HDF JARs to Local Maven Repository
      shell: pwsh
      run: |
        New-Item -Path "repository\lib" -ItemType Directory -Force | Out-Null
        if (Test-Path "$env:HDF4LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF4LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "$env:HDF5LIB_PATH\lib\*.jar") {
          Copy-Item "$env:HDF5LIB_PATH\lib\*.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\fits.jar") {
          Copy-Item "lib\fits.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        if (Test-Path "lib\netcdf.jar") {
          Copy-Item "lib\netcdf.jar" -Destination "repository\lib\" -ErrorAction SilentlyContinue
        }
        $jarhdf5 = Get-ChildItem "repository\lib\jarhdf5-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf5) {
          $HDF5_VERSION = $jarhdf5.Name -replace 'jarhdf5-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf5.FullName)" `
            "-DgroupId=jarhdf5" "-DartifactId=jarhdf5" "-Dversion=$HDF5_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf5.Name) as version $HDF5_VERSION"
          "HDF5_VERSION=$HDF5_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }
        $jarhdf = Get-ChildItem "repository\lib\jarhdf-*.jar" -ErrorAction SilentlyContinue | Select-Object -First 1
        if ($jarhdf) {
          $HDF4_VERSION = $jarhdf.Name -replace 'jarhdf-([0-9.]+)\.jar', '$1'
          mvn install:install-file "-Dfile=$($jarhdf.FullName)" `
            "-DgroupId=jarhdf" "-DartifactId=jarhdf" "-Dversion=$HDF4_VERSION" "-Dpackaging=jar" "-DgeneratePom=true"
          Write-Host "Installed: $($jarhdf.Name) as version $HDF4_VERSION"
          "HDF4_VERSION=$HDF4_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        }
        if (Test-Path "repository\lib\fits.jar") {
          mvn install:install-file "-Dfile=repository\lib\fits.jar" `
            "-DgroupId=fits" "-DartifactId=fits" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }
        if (Test-Path "repository\lib\netcdf.jar") {
          mvn install:install-file "-Dfile=repository\lib\netcdf.jar" `
            "-DgroupId=netcdf" "-DartifactId=netcdf" "-Dversion=1.0.0" "-Dpackaging=jar" "-DgeneratePom=true"
        }

    - name: Build repository module (copies platform SWT JAR)
      shell: pwsh
      run: |
        Write-Host "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing Windows SWT JAR to local Maven repository..."
        if (Test-Path "repository\lib\swt.jar") {
          mvn install:install-file "-Dfile=repository\lib\swt.jar" `
            "-DgroupId=org.eclipse.platform" `
            "-DartifactId=org.eclipse.swt.win32.win32.amd64" `
            "-Dversion=3.126.0" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "Windows SWT JAR installed"
        } else {
          Write-Error "swt.jar not found in repository/lib/"
          exit 1
        }

    - name: Install SWTBot JARs to Local Maven Repository
      shell: pwsh
      run: |
        Write-Host "Installing SWTBot JARs to local Maven repository..."

        if (Test-Path "repository\lib\org.eclipse.swtbot.swt.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.swt.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.swt.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot SWT finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        }

        if (Test-Path "repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar") {
          mvn install:install-file "-Dfile=repository\lib\org.eclipse.swtbot.nebula.nattable.finder.jar" `
            "-DgroupId=org.eclipse.local" `
            "-DartifactId=org.eclipse.swtbot.nebula.nattable.finder" `
            "-Dversion=4.2.1" `
            "-Dpackaging=jar" `
            "-DgeneratePom=true"
          Write-Host "SWTBot Nebula NatTable finder JAR installed"
        } else {
          Write-Host "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        }

    - name: Build and Package Application
      shell: pwsh
      run: |
        Write-Host "Building HDFView with Maven..."
        # Install parent POM first (required for child module resolution)
        mvn install -B -N "-Ddependency-check.skip=true"

        # Install object and hdfview modules (needed for jpackage)
        mvn install -B -pl object,hdfview -DskipTests "-Ddependency-check.skip=true"

        # Package application
        mvn package -DskipTests -B

    - name: Prepare jpackage Input Directory
      shell: pwsh
      run: |
        Write-Host "Preparing jpackage input directory manually (Windows-specific fix)..."
        Write-Host "This step manually prepares the staging directory to ensure native libraries are included."
        Write-Host ""

        # Create staging directory
        $JPACKAGE_INPUT = "hdfview\target\jpackage-input"
        Write-Host "Creating staging directory: $JPACKAGE_INPUT"
        if (Test-Path $JPACKAGE_INPUT) {
          Remove-Item -Recurse -Force $JPACKAGE_INPUT
        }
        New-Item -ItemType Directory -Path $JPACKAGE_INPUT | Out-Null

        # Copy main JARs from libs/
        Write-Host "Copying main JARs from libs/..."
        Copy-Item "libs\hdfview-*.jar" $JPACKAGE_INPUT\ -ErrorAction Stop
        Copy-Item "libs\object-*.jar" $JPACKAGE_INPUT\ -ErrorAction Stop
        Write-Host "  ✓ Main JARs copied"

        # Copy all runtime dependencies from hdfview/target/lib
        Write-Host "Copying runtime dependencies from hdfview\target\lib..."
        $jarCount = (Get-ChildItem "hdfview\target\lib\*.jar").Count
        Copy-Item "hdfview\target\lib\*.jar" $JPACKAGE_INPUT\ -ErrorAction Stop
        Write-Host "  ✓ Copied $jarCount dependency JARs"

        # Copy HDF5 native libraries
        Write-Host "Copying HDF5 native libraries from $env:HDF5LIB_PATH..."
        if (Test-Path "$env:HDF5LIB_PATH\bin") {
          $hdf5Dlls = Get-ChildItem "$env:HDF5LIB_PATH\bin\*.dll" -ErrorAction SilentlyContinue
          if ($hdf5Dlls) {
            Copy-Item "$env:HDF5LIB_PATH\bin\*.dll" $JPACKAGE_INPUT\ -ErrorAction Stop
            Write-Host "  ✓ Copied $($hdf5Dlls.Count) HDF5 DLLs"
          } else {
            Write-Warning "  ⚠ No HDF5 DLLs found in $env:HDF5LIB_PATH\bin"
          }
        } else {
          Write-Error "  ✗ HDF5 bin directory not found: $env:HDF5LIB_PATH\bin"
          exit 1
        }

        # Copy HDF4 native libraries
        Write-Host "Copying HDF4 native libraries from $env:HDF4LIB_PATH..."
        if (Test-Path "$env:HDF4LIB_PATH\bin") {
          $hdf4Dlls = Get-ChildItem "$env:HDF4LIB_PATH\bin\*.dll" -ErrorAction SilentlyContinue
          if ($hdf4Dlls) {
            Copy-Item "$env:HDF4LIB_PATH\bin\*.dll" $JPACKAGE_INPUT\ -ErrorAction Stop
            Write-Host "  ✓ Copied $($hdf4Dlls.Count) HDF4 DLLs"
          } else {
            Write-Warning "  ⚠ No HDF4 DLLs found in $env:HDF4LIB_PATH\bin"
          }
        } else {
          Write-Error "  ✗ HDF4 bin directory not found: $env:HDF4LIB_PATH\bin"
          exit 1
        }

        # Copy HDF5 plugins
        Write-Host "Copying HDF5 plugins..."
        $pluginDir = "$JPACKAGE_INPUT\plugin"
        New-Item -ItemType Directory -Path $pluginDir -Force | Out-Null
        if (Test-Path "$env:HDF5_PLUGIN_PATH") {
          $plugins = Get-ChildItem "$env:HDF5_PLUGIN_PATH\*.dll" -ErrorAction SilentlyContinue
          if ($plugins) {
            Copy-Item "$env:HDF5_PLUGIN_PATH\*.dll" $pluginDir\ -ErrorAction Stop
            Write-Host "  ✓ Copied $($plugins.Count) plugin DLLs"
          } else {
            Write-Host "  ⓘ No plugins found"
          }
        } else {
          Write-Host "  ⓘ HDF5_PLUGIN_PATH not set, skipping plugins"
        }

        # Copy samples
        Write-Host "Copying sample files..."
        $samplesDir = "$JPACKAGE_INPUT\samples"
        New-Item -ItemType Directory -Path $samplesDir -Force | Out-Null
        if (Test-Path "samples") {
          Copy-Item "samples\*" $samplesDir\ -Recurse -ErrorAction Stop
          $sampleCount = (Get-ChildItem $samplesDir -File).Count
          Write-Host "  ✓ Copied $sampleCount sample files"
        } else {
          Write-Warning "  ⚠ samples directory not found"
        }

        # Copy documentation
        Write-Host "Copying documentation..."
        $docDir = "$JPACKAGE_INPUT\doc"
        New-Item -ItemType Directory -Path $docDir -Force | Out-Null
        if (Test-Path "docs\UsersGuide") {
          Copy-Item "docs\UsersGuide\*" $docDir\ -Recurse -Include "*.md","*.txt","*.html","*.png","*.jpg","*.gif" -ErrorAction Stop
          $docCount = (Get-ChildItem $docDir -Recurse -File).Count
          Write-Host "  ✓ Copied $docCount documentation files"
        } else {
          Write-Warning "  ⚠ docs\UsersGuide directory not found"
        }

        Write-Host ""
        Write-Host "=== Staging directory prepared ==="
        Write-Host "Total files: $((Get-ChildItem $JPACKAGE_INPUT -Recurse -File).Count)"
        Write-Host "Total size: $([math]::Round((Get-ChildItem $JPACKAGE_INPUT -Recurse -File | Measure-Object -Property Length -Sum).Sum / 1MB, 2)) MB"
        Write-Host "JAR files: $((Get-ChildItem $JPACKAGE_INPUT -Filter *.jar).Count)"
        Write-Host "DLL files: $((Get-ChildItem $JPACKAGE_INPUT -Recurse -Filter *.dll).Count)"
        Write-Host ""

    - name: Create jpackage App Image
      shell: pwsh
      run: |
        Write-Host "Creating distributable application package with jpackage..."

        # Create app-image using jpackage profile
        # -pl object,hdfview: Build object and hdfview modules (skip repository)
        # -Dmaven.test.skip=true: Skip test compilation and execution
        # -Djacoco.skip=true: Skip JaCoCo (not needed for release builds)
        # -Dpmd.skip=true: Skip PMD (static analysis not needed for release)
        # -Ddependency-check.skip=true: Skip OWASP (runs in separate security workflow)
        # -Dmaven.antrun.skip=true: Skip Ant plugin (we manually prepared the input directory)
        mvn verify -Pjpackage-app-image -pl object,hdfview `
          "-Dmaven.test.skip=true" `
          "-Djacoco.skip=true" `
          "-Dpmd.skip=true" `
          "-Ddependency-check.skip=true" `
          "-Dmaven.antrun.skip=true" `
          -B

        Write-Host "Verifying jpackage output..."
        if (Test-Path "hdfview\target\dist\HDFView") {
          Write-Host "✓ jpackage app-image created successfully"
          $size = (Get-ChildItem -Recurse "hdfview\target\dist\HDFView" | Measure-Object -Property Length -Sum).Sum / 1MB
          Write-Host "Package size: $([math]::Round($size, 2)) MB"
          $dlls = (Get-ChildItem -Recurse "hdfview\target\dist\HDFView\lib\app\*.dll" -ErrorAction SilentlyContinue).Count
          Write-Host "Native libraries: $dlls .dll files"
          $jars = (Get-ChildItem -Recurse "hdfview\target\dist\HDFView\lib\app\*.jar" -ErrorAction SilentlyContinue).Count
          Write-Host "JAR files: $jars JARs"
        } else {
          Write-Error "✗ jpackage app-image creation failed"
          exit 1
        }

    - name: Create Windows Application Archive
      shell: pwsh
      run: |
        # Package the jpackage app-image as a ZIP for distribution
        # Note: Must preserve HDFView directory structure for jpackage --app-image to work
        Set-Location "hdfview\target\dist"
        Compress-Archive -Path "HDFView" -DestinationPath "${{ github.workspace }}\${{ inputs.artifact_basename }}App-win64.zip"

        Write-Host "Windows application archive created: ${{ inputs.artifact_basename }}App-win64.zip"
        Get-Item "${{ github.workspace }}\${{ inputs.artifact_basename }}App-win64.zip" | Select-Object Name, Length

    - name: Upload Windows App Artifact
      uses: actions/upload-artifact@v4
      with:
        name: zip-win-vs2022-app-binary
        path: ${{ inputs.artifact_basename }}App-win64.zip
        retention-days: 30

  build-macos:
    name: Build macOS Binary
    runs-on: macos-latest
    timeout-minutes: 30
    env:
      # Repository variables for signing (matching ant.yml)
      KEYCHAIN_NAME: ${{ vars.KEYCHAIN_NAME }}
      SIGNER: ${{ vars.SIGNER }}
      # Secrets for keychain setup
      APPLE_CERTS_BASE64: ${{ secrets.APPLE_CERTS_BASE64 }}
      APPLE_CERTS_BASE64_PASSWD: ${{ secrets.APPLE_CERTS_BASE64_PASSWD }}
      KEYCHAIN_PASSWD: ${{ secrets.KEYCHAIN_PASSWD }}

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.hdf4_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf4_artifact_basename }}" ]; then
          PATTERN="${{ inputs.hdf4_artifact_basename }}-macos14_clang.tar.gz"
        else
          PATTERN="*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf4_version_tag }}" \
          --repo HDFGroup/hdf4 \
          --pattern "$PATTERN" \
          --clobber

        echo "Extracting HDF4..."
        tar -zxvf *-macos14_clang.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4
        cd hdf4
        tar -zxvf HDF-*-Darwin.tar.gz --strip-components 1

        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME=$(ls $HDF4DIR)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME" >> $GITHUB_ENV
        echo "HDF4 installed to: $HDF4DIR$FILE_NAME"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.hdf5_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf5_artifact_basename }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.hdf5_artifact_basename }}-macos14_clang.tar.gz"
        else
          PATTERN="hdf5-*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf5_version_tag }}" \
          --repo HDFGroup/hdf5 \
          --pattern "$PATTERN" \
          --clobber

        echo "Extracting HDF5..."
        tar -zxvf hdf5-*-macos14_clang.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5
        cd hdf5
        tar -zxvf HDF5-*-Darwin.tar.gz --strip-components 1

        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME=$(ls $HDF5DIR)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME" >> $GITHUB_ENV
        echo "HDF5 installed to: $HDF5DIR$FILE_NAME"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties <<EOF
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

        echo "Generated build.properties:"
        cat build.properties

    - name: Install HDF JARs to Local Maven Repository
      run: |
        echo "Installing HDF JARs to local Maven repository..."
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs"
        cp lib/fits.jar repository/lib/ 2>/dev/null || echo "fits.jar not found"
        cp lib/netcdf.jar repository/lib/ 2>/dev/null || echo "netcdf.jar not found"

        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi

        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi

        # Install fits
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: fits.jar"
        else
          echo "ERROR: fits.jar not found in repository/lib/"
          exit 1
        fi

        # Install netcdf
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed: netcdf.jar"
        else
          echo "ERROR: netcdf.jar not found in repository/lib/"
          exit 1
        fi

    - name: Build repository module (copies platform SWT JAR)
      run: |
        echo "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      run: |
        echo "Installing macOS SWT JAR to local Maven repository..."
        if [ -f repository/lib/swt.jar ]; then
          mvn install:install-file -Dfile=repository/lib/swt.jar \
            -DgroupId=org.eclipse.platform \
            -DartifactId=org.eclipse.swt.cocoa.macosx.amd64 \
            -Dversion=3.126.0 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "macOS SWT JAR installed"
        else
          echo "ERROR: swt.jar not found in repository/lib/"
          exit 1
        fi

    - name: Install SWTBot JARs to Local Maven Repository
      run: |
        echo "Installing SWTBot JARs to local Maven repository..."

        if [ -f repository/lib/org.eclipse.swtbot.swt.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.swt.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.swt.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot SWT finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        fi

        if [ -f repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.nebula.nattable.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot Nebula NatTable finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        fi

    - name: Build with Maven
      run: |
        echo "Building HDFView with Maven..."
        # Build object and hdfview modules, stop at package phase to avoid verify/PMD
        mvn package -pl object,hdfview -Dmaven.test.skip=true -Dhdf5.version="$HDF5_VERSION" -Dhdf.version="$HDF4_VERSION" -B

    - name: Create macOS Binary Archive
      run: |
        mkdir -p hdfview-dist

        # Copy JARs
        cp libs/*.jar hdfview-dist/
        cp hdfview/target/*.jar hdfview-dist/ 2>/dev/null || true
        cp object/target/*.jar hdfview-dist/ 2>/dev/null || true

        # Create lib directory and copy dylibs
        mkdir -p hdfview-dist/lib
        cp -L ${{ env.HDF4LIB_PATH }}/lib/*.dylib hdfview-dist/lib/ 2>/dev/null || true
        cp -L ${{ env.HDF5LIB_PATH }}/lib/*.dylib hdfview-dist/lib/ 2>/dev/null || true

        # Create tar.gz archive
        tar -czf ${{ inputs.artifact_basename }}-Darwin.tar.gz -C hdfview-dist .

    - name: Upload macOS Binary Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-macos14_clang-binary
        path: ${{ inputs.artifact_basename }}-Darwin.tar.gz
        retention-days: 30

  build-macos-app:
    name: Build macOS DMG Installer
    runs-on: macos-latest
    timeout-minutes: 30
    env:
      # Repository variables (matching ant.yml and build.xml)
      KEYCHAIN_NAME: ${{ vars.KEYCHAIN_NAME }}
      SIGNER: ${{ vars.SIGNER }}
      NOTARY_USER: ${{ vars.NOTARY_USER }}
      NOTARY_KEY: ${{ vars.NOTARY_KEY }}
      # Secrets for signing
      APPLE_CERTS_BASE64: ${{ secrets.APPLE_CERTS_BASE64 }}
      APPLE_CERTS_BASE64_PASSWD: ${{ secrets.APPLE_CERTS_BASE64_PASSWD }}
      KEYCHAIN_PASSWD: ${{ secrets.KEYCHAIN_PASSWD }}

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Extract version from VERSION file
      id: get-version
      run: |
        HDFVIEW_VERSION=$(grep "^HDFVIEW_VERSION=" VERSION | cut -d'=' -f2)
        echo "HDFVIEW_VERSION=$HDFVIEW_VERSION" >> $GITHUB_OUTPUT
        echo "HDFView version: $HDFVIEW_VERSION"

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.m2/repository
          !~/.m2/repository/org/hdfgroup
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - name: Download and Install HDF4 from GitHub
      run: |
        echo "Downloading HDF4 from release tag: ${{ inputs.hdf4_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf4_artifact_basename }}" ]; then
          PATTERN="${{ inputs.hdf4_artifact_basename }}-macos14_clang.tar.gz"
        else
          PATTERN="*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf4_version_tag }}" --repo HDFGroup/hdf4 --pattern "$PATTERN" \
          --clobber
        tar -zxvf *-macos14_clang.tar.gz
        [ -d hdf4 ] || mv hdf4-* hdf4
        cd hdf4
        tar -zxvf HDF-*-Darwin.tar.gz --strip-components 1
        HDF4DIR=${{ github.workspace }}/hdf4/HDF_Group/HDF/
        FILE_NAME=$(ls $HDF4DIR)
        echo "HDF4LIB_PATH=$HDF4DIR$FILE_NAME" >> $GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Download and Install HDF5 from GitHub
      run: |
        echo "Downloading HDF5 from release tag: ${{ inputs.hdf5_version_tag }}"

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf5_artifact_basename }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.hdf5_artifact_basename }}-macos14_clang.tar.gz"
        else
          PATTERN="hdf5-*-macos14_clang.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        gh release download "${{ inputs.hdf5_version_tag }}" --repo HDFGroup/hdf5 --pattern "$PATTERN" \
          --clobber
        tar -zxvf hdf5-*-macos14_clang.tar.gz
        [ -d hdf5 ] || mv hdf5-* hdf5
        cd hdf5
        tar -zxvf HDF5-*-Darwin.tar.gz --strip-components 1
        HDF5DIR=${{ github.workspace }}/hdf5/HDF_Group/HDF5/
        FILE_NAME=$(ls $HDF5DIR)
        echo "HDF5LIB_PATH=$HDF5DIR$FILE_NAME" >> $GITHUB_ENV
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties <<EOF
        hdf5.lib.dir=${{ env.HDF5LIB_PATH }}/lib
        hdf5.plugin.dir=${{ env.HDF5LIB_PATH }}/lib/plugin
        hdf.lib.dir=${{ env.HDF4LIB_PATH }}/lib
        platform.hdf.lib=${{ env.HDF5LIB_PATH }}/lib
        EOF

    - name: Install HDF JARs to Local Maven Repository
      run: |
        mkdir -p repository/lib
        cp ${{ env.HDF4LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF4 JARs"
        cp ${{ env.HDF5LIB_PATH }}/lib/*.jar repository/lib/ 2>/dev/null || echo "No HDF5 JARs"
        cp lib/fits.jar repository/lib/ 2>/dev/null || echo "fits.jar not found"
        cp lib/netcdf.jar repository/lib/ 2>/dev/null || echo "netcdf.jar not found"
        if [ -f repository/lib/jarhdf5-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf5-*.jar | head -1)
          HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF5_VERSION"
          echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
        fi
        if [ -f repository/lib/jarhdf-*.jar ]; then
          JAR_FILE=$(ls repository/lib/jarhdf-*.jar | head -1)
          HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
          mvn install:install-file -Dfile="$JAR_FILE" -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" -Dpackaging=jar -DgeneratePom=true
          echo "Installed: $JAR_FILE as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        fi
        if [ -f repository/lib/fits.jar ]; then
          mvn install:install-file -Dfile=repository/lib/fits.jar \
            -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 -Dpackaging=jar -DgeneratePom=true
        fi
        if [ -f repository/lib/netcdf.jar ]; then
          mvn install:install-file -Dfile=repository/lib/netcdf.jar \
            -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 -Dpackaging=jar -DgeneratePom=true
        fi

    - name: Build repository module (copies platform SWT JAR)
      run: |
        echo "Building repository module to copy SWT JAR..."
        # Only run generate-sources phase to trigger antrun plugin (copies SWT JAR)
        # This avoids the verify phase which would trigger PMD
        mvn generate-sources -pl repository -B

    - name: Install SWT JAR to Local Maven Repository
      run: |
        echo "Installing macOS SWT JAR to local Maven repository..."
        if [ -f repository/lib/swt.jar ]; then
          mvn install:install-file -Dfile=repository/lib/swt.jar \
            -DgroupId=org.eclipse.platform \
            -DartifactId=org.eclipse.swt.cocoa.macosx.amd64 \
            -Dversion=3.126.0 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "macOS SWT JAR installed"
        else
          echo "ERROR: swt.jar not found in repository/lib/"
          exit 1
        fi

    - name: Install SWTBot JARs to Local Maven Repository
      run: |
        echo "Installing SWTBot JARs to local Maven repository..."

        if [ -f repository/lib/org.eclipse.swtbot.swt.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.swt.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.swt.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot SWT finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.swt.finder.jar not found"
        fi

        if [ -f repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar ]; then
          mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar \
            -DgroupId=org.eclipse.local \
            -DartifactId=org.eclipse.swtbot.nebula.nattable.finder \
            -Dversion=4.2.1 \
            -Dpackaging=jar \
            -DgeneratePom=true
          echo "SWTBot Nebula NatTable finder JAR installed"
        else
          echo "WARNING: org.eclipse.swtbot.nebula.nattable.finder.jar not found"
        fi

    - name: Build and Package Application
      run: |
        echo "Building HDFView with Maven..."
        # Install parent POM first (required for child module resolution)
        mvn install -B -N -Ddependency-check.skip=true

        # Install object and hdfview modules (needed for jpackage)
        mvn install -B -pl object,hdfview -DskipTests -Ddependency-check.skip=true

        # Package application
        mvn package -DskipTests -B

    - name: Setup Keychain for Code Signing
      if: github.repository == 'HDFGroup/hdfview' && env.APPLE_CERTS_BASE64 != ''
      run: |
        echo "Setting up temporary keychain for code signing..."

        # Create variables (matching ant.yml and build.xml)
        CERTIFICATE_PATH=$RUNNER_TEMP/build_certificate.p12
        KEYCHAIN_FILE=$KEYCHAIN_NAME.keychain

        # Import certificate from secrets
        echo $APPLE_CERTS_BASE64 | base64 --decode > $CERTIFICATE_PATH

        # Create and configure keychain (matching ant.yml)
        security -v create-keychain -p $KEYCHAIN_PASSWD $KEYCHAIN_FILE
        security -v list-keychain -d user -s $KEYCHAIN_FILE
        security -v list-keychains
        security -v set-keychain-settings -lut 21600 $KEYCHAIN_FILE
        security -v unlock-keychain -p $KEYCHAIN_PASSWD $KEYCHAIN_FILE

        # Import certificate to keychain
        security -v import $CERTIFICATE_PATH -P $APPLE_CERTS_BASE64_PASSWD -A -t cert -f pkcs12 -k $KEYCHAIN_FILE
        security -v set-key-partition-list -S apple-tool:,codesign:,apple: -k $KEYCHAIN_PASSWD $KEYCHAIN_FILE

        # Clean up certificate file
        rm $CERTIFICATE_PATH

        echo "✓ Keychain setup complete"
        echo "✓ Code signing identity: $SIGNER"

    - name: Prepare jpackage Input Directory
      run: |
        echo "Preparing jpackage input directory manually..."

        # Debug: Show what's available
        echo "=== Available JAR files ==="
        echo "In libs/:"
        ls -lh libs/*.jar 2>/dev/null || echo "  No libs/ directory or no JARs"
        echo "In hdfview/target/:"
        ls -lh hdfview/target/*.jar 2>/dev/null || echo "  No JARs in hdfview/target/"
        echo ""

        # Create staging directory
        JPACKAGE_INPUT=hdfview/target/jpackage-input
        rm -rf $JPACKAGE_INPUT
        mkdir -p $JPACKAGE_INPUT

        # Copy main JAR - try both locations
        echo "Copying main JAR..."
        if ls libs/hdfview-*.jar 1> /dev/null 2>&1; then
          cp libs/hdfview-*.jar $JPACKAGE_INPUT/
          echo "  Copied from libs/"
        elif ls hdfview/target/hdfview-*.jar 1> /dev/null 2>&1; then
          cp hdfview/target/hdfview-*.jar $JPACKAGE_INPUT/
          echo "  Copied from hdfview/target/"
        else
          echo "  ERROR: hdfview JAR not found!"
          exit 1
        fi

        # Copy object module JAR
        echo "Copying object module JAR..."
        if ls libs/object-*.jar 1> /dev/null 2>&1; then
          cp libs/object-*.jar $JPACKAGE_INPUT/
          echo "  Copied from libs/"
        elif ls object/target/object-*.jar 1> /dev/null 2>&1; then
          cp object/target/object-*.jar $JPACKAGE_INPUT/
          echo "  Copied from object/target/"
        else
          echo "  ERROR: object JAR not found!"
          exit 1
        fi

        # Copy all dependencies from target/lib
        echo "Copying dependencies from target/lib..."
        if [ -d hdfview/target/lib ]; then
          cp hdfview/target/lib/*.jar $JPACKAGE_INPUT/ || echo "No dependency JARs found"
        fi

        # Copy HDF5 native libraries
        echo "Copying HDF5 native libraries from ${{ env.HDF5LIB_PATH }}/lib..."
        cp -L ${{ env.HDF5LIB_PATH }}/lib/*.dylib $JPACKAGE_INPUT/ 2>/dev/null || echo "No HDF5 dylibs"
        cp -L ${{ env.HDF5LIB_PATH }}/lib/*.jar $JPACKAGE_INPUT/ 2>/dev/null || echo "No HDF5 JARs"

        # Copy HDF4 native libraries
        echo "Copying HDF4 native libraries from ${{ env.HDF4LIB_PATH }}/lib..."
        cp -L ${{ env.HDF4LIB_PATH }}/lib/*.dylib $JPACKAGE_INPUT/ 2>/dev/null || echo "No HDF4 dylibs"
        cp -L ${{ env.HDF4LIB_PATH }}/lib/*.jar $JPACKAGE_INPUT/ 2>/dev/null || echo "No HDF4 JARs"

        # Copy HDF5 plugins
        echo "Copying HDF5 plugins..."
        mkdir -p $JPACKAGE_INPUT/plugin
        cp -L ${{ env.HDF5LIB_PATH }}/lib/plugin/*.dylib $JPACKAGE_INPUT/plugin/ 2>/dev/null || echo "No HDF5 plugins"

        echo ""
        echo "=== jpackage input directory prepared ==="
        ls -lh $JPACKAGE_INPUT/
        echo ""
        echo "JAR count: $(find $JPACKAGE_INPUT -name "*.jar" | wc -l)"
        echo "Dylib count: $(find $JPACKAGE_INPUT -name "*.dylib" | wc -l)"
        echo "Plugin count: $(ls -1 $JPACKAGE_INPUT/plugin/*.dylib 2>/dev/null | wc -l)"

    - name: Create Signed App Image with jpackage
      if: github.repository == 'HDFGroup/hdfview' && env.APPLE_CERTS_BASE64 != ''
      run: |
        echo "Creating SIGNED app-image with jpackage (matching build.xml approach)..."

        # Unlock keychain (matching build.xml line 2099-2105)
        security unlock-keychain -p $KEYCHAIN_PASSWD $KEYCHAIN_NAME.keychain

        # Create dist directory
        mkdir -p hdfview/target/dist

        # Determine the actual main JAR filename from what was copied
        MAIN_JAR=$(basename hdfview/target/jpackage-input/hdfview-*.jar)
        echo "Main JAR: $MAIN_JAR"

        # Call jpackage directly with --mac-sign (matching build.xml lines 2270-2343)
        $JAVA_HOME/bin/jpackage \
          --verbose \
          --name HDFView \
          --input hdfview/target/jpackage-input \
          --main-jar "$MAIN_JAR" \
          --main-class hdf.view.HDFView \
          --dest hdfview/target/dist \
          --type app-image \
          --app-version ${{ steps.get-version.outputs.HDFVIEW_VERSION }} \
          --mac-sign \
          --mac-package-identifier HDFView.hdfgroup.org \
          --mac-package-name HDFView-${{ steps.get-version.outputs.HDFVIEW_VERSION }} \
          --mac-package-signing-prefix org.hdfgroup.HDFView \
          --mac-signing-key-user-name "The HDF Group ($SIGNER)"

        echo "✓ Signed app-image created successfully"

    - name: Create Unsigned App Image with Maven
      if: github.repository != 'HDFGroup/hdfview' || env.APPLE_CERTS_BASE64 == ''
      run: |
        echo "Creating UNSIGNED app-image using Maven profile (fork or no secrets)..."

        mvn verify -Pjpackage-app-image -pl object,hdfview \
          -Dmaven.test.skip=true \
          -Djacoco.skip=true \
          -Dpmd.skip=true \
          -Ddependency-check.skip=true \
          -B

        echo "✓ Unsigned app-image created"

    - name: Verify App Image Creation
      run: |
        echo "Verifying jpackage output..."
        if [ -d hdfview/target/dist/HDFView.app ]; then
          echo "✓ jpackage app-image created successfully"
          echo "Package size: $(du -sh hdfview/target/dist/HDFView.app | cut -f1)"
          echo "Native libraries: $(find hdfview/target/dist/HDFView.app/Contents -name "*.dylib" 2>/dev/null | wc -l) .dylib files"
          echo "JAR files: $(find hdfview/target/dist/HDFView.app/Contents -name "*.jar" 2>/dev/null | wc -l) JARs"
          echo "HDF5 plugins: $(ls -1 hdfview/target/dist/HDFView.app/Contents/app/plugin/*.dylib 2>/dev/null | wc -l) plugins"

          # Verify code signature if signed
          if [ "${{ github.repository }}" = "HDFGroup/hdfview" ] && [ -n "$APPLE_CERTS_BASE64" ]; then
            echo ""
            echo "=== Verifying Code Signatures ==="
            codesign -vvv --deep --strict hdfview/target/dist/HDFView.app 2>&1 | head -20
          fi
        else
          echo "✗ jpackage app-image creation failed"
          exit 1
        fi

    - name: Create macOS Application Archive
      run: |
        # Package the jpackage app-image as a tar.gz for distribution
        cd hdfview/target/dist
        tar -czf ${{ github.workspace }}/${{ inputs.artifact_basename }}App-Darwin.tar.gz HDFView.app/

        echo "macOS application archive created: ${{ inputs.artifact_basename }}App-Darwin.tar.gz"
        ls -lh ${{ github.workspace }}/${{ inputs.artifact_basename }}App-Darwin.tar.gz

    - name: Create DMG Installer
      run: |
        echo "Creating DMG installer from app-image..."

        cd hdfview/target/dist

        # Use jpackage to create DMG from existing app-image
        $JAVA_HOME/bin/jpackage \
          --type dmg \
          --app-image HDFView.app \
          --name HDFView \
          --app-version ${{ steps.get-version.outputs.HDFVIEW_VERSION }} \
          --mac-package-identifier HDFView.hdfgroup.org \
          --mac-package-name "HDFView-${{ steps.get-version.outputs.HDFVIEW_VERSION }}" \
          --file-associations ${{ github.workspace }}/package_files/HDFViewHDF.properties \
          --file-associations ${{ github.workspace }}/package_files/HDFViewH4.properties \
          --file-associations ${{ github.workspace }}/package_files/HDFViewHDF4.properties \
          --file-associations ${{ github.workspace }}/package_files/HDFViewH5.properties \
          --file-associations ${{ github.workspace }}/package_files/HDFViewHDF5.properties \
          --dest .

        echo "DMG installer created successfully"
        ls -lh *.dmg

    - name: Rename DMG for Snapshots
      if: inputs.use_environ == 'snapshots'
      run: |
        cd hdfview/target/dist
        # For snapshots, rename DMG to include commit SHA (file_base)
        OLD_NAME="HDFView-${{ steps.get-version.outputs.HDFVIEW_VERSION }}.dmg"
        NEW_NAME="${{ inputs.file_base }}.dmg"
        echo "Renaming $OLD_NAME to $NEW_NAME"
        mv "$OLD_NAME" "$NEW_NAME"
        ls -lh *.dmg

    - name: Notarize DMG Installer
      if: github.repository == 'HDFGroup/hdfview' && env.APPLE_CERTS_BASE64 != ''
      run: |
        echo "Submitting DMG for notarization..."

        cd hdfview/target/dist

        # Determine DMG filename (snapshot includes commit SHA, release uses version only)
        if [ "${{ inputs.use_environ }}" = "snapshots" ]; then
          DMG_FILE="${{ inputs.file_base }}.dmg"
        else
          DMG_FILE="HDFView-${{ steps.get-version.outputs.HDFVIEW_VERSION }}.dmg"
        fi

        echo "DMG file: $DMG_FILE"

        # Submit for notarization using xcrun notarytool (matching build.xml)
        xcrun notarytool submit "$DMG_FILE" \
          --apple-id "$NOTARY_USER" \
          --password "$NOTARY_KEY" \
          --team-id "$SIGNER" \
          --wait \
          --timeout 30m \
          --output-format json > notarization-response.json

        cat notarization-response.json

        # Check notarization status
        STATUS=$(cat notarization-response.json | grep -o '"status":"[^"]*"' | cut -d'"' -f4)
        SUBMISSION_ID=$(cat notarization-response.json | grep -o '"id":"[^"]*"' | head -1 | cut -d'"' -f4)

        echo "Notarization status: $STATUS"
        echo "Submission ID: $SUBMISSION_ID"

        if [ "$STATUS" = "Accepted" ]; then
          echo "✓ Notarization successful"
        else
          echo "✗ Notarization failed with status: $STATUS"
          echo ""
          echo "=== Fetching Detailed Notarization Log ==="
          if [ -n "$SUBMISSION_ID" ]; then
            xcrun notarytool log "$SUBMISSION_ID" \
              --apple-id "$NOTARY_USER" \
              --password "$NOTARY_KEY" \
              --team-id "$SIGNER" || echo "Failed to fetch log"
          fi
          exit 1
        fi

    - name: Staple Notarization to DMG
      if: github.repository == 'HDFGroup/hdfview' && env.APPLE_CERTS_BASE64 != ''
      run: |
        echo "Stapling notarization ticket to DMG..."

        cd hdfview/target/dist

        # Determine DMG filename
        if [ "${{ inputs.use_environ }}" = "snapshots" ]; then
          DMG_FILE="${{ inputs.file_base }}.dmg"
        else
          DMG_FILE="HDFView-${{ steps.get-version.outputs.HDFVIEW_VERSION }}.dmg"
        fi

        # Staple the notarization ticket
        xcrun stapler staple "$DMG_FILE"

        # Verify stapling
        xcrun stapler validate "$DMG_FILE"

        echo "✓ Notarization ticket stapled successfully"

    - name: Upload macOS App Artifact
      uses: actions/upload-artifact@v4
      with:
        name: tgz-macos14_clang-app-binary
        path: ${{ inputs.artifact_basename }}App-Darwin.tar.gz
        retention-days: 30

    - name: Upload macOS DMG Installer Artifact
      uses: actions/upload-artifact@v4
      with:
        # Artifact name matches what release-files.yml expects
        name: ${{ inputs.use_environ == 'snapshots' && format('{0}-macOS-dmg', inputs.file_base) || format('HDFView-{0}-macOS-dmg', steps.get-version.outputs.HDFVIEW_VERSION) }}
        path: hdfview/target/dist/*.dmg
        retention-days: 30

  build-linux-installers:
    name: Build Linux Installers (DEB/RPM)
    runs-on: ubuntu-latest
    needs: build-linux-app
    timeout-minutes: 20

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Download Linux App Artifact
      uses: actions/download-artifact@v4
      with:
        name: tgz-ubuntu-2404-app-binary

    - name: Extract App Image
      run: |
        tar -xzf ${{ inputs.artifact_basename }}App-Linux-x86_64.tar.gz
        ls -la HDFView/

    - name: Create DEB Installer
      run: |
        echo "DEB installer creation - to be implemented"
        echo "Requires jpackage-deb profile and package files"
        # TODO: Implement DEB creation once jpackage profile is ready

    - name: Create RPM Installer
      run: |
        echo "RPM installer creation - to be implemented"
        echo "Requires jpackage-rpm profile and package files"
        # TODO: Implement RPM creation once jpackage profile is ready

  build-windows-installer:
    name: Build Windows Installer (MSI)
    runs-on: windows-latest
    needs: build-windows-app
    timeout-minutes: 20
    env:
      # Set secrets as env vars at job level so they can be checked in step conditions
      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
      AZURE_ENDPOINT: ${{ secrets.AZURE_ENDPOINT }}
      AZURE_CODE_SIGNING_NAME: ${{ secrets.AZURE_CODE_SIGNING_NAME }}
      AZURE_CERT_PROFILE_NAME: ${{ secrets.AZURE_CERT_PROFILE_NAME }}

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Extract version from VERSION file
      id: get-version
      shell: pwsh
      run: |
        # Read HDFVIEW_VERSION from VERSION file
        $version = (Get-Content VERSION | Select-String "^HDFVIEW_VERSION=").ToString().Split('=')[1]
        echo "HDFVIEW_VERSION=$version" >> $env:GITHUB_OUTPUT
        Write-Host "HDFView version: $version"

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Download Windows App Artifact
      uses: actions/download-artifact@v4
      with:
        name: zip-win-vs2022-app-binary

    - name: Extract App Image
      shell: pwsh
      run: |
        Expand-Archive -Path "${{ inputs.artifact_basename }}App-win64.zip" -DestinationPath .
        Get-ChildItem -Recurse

    - name: Create MSI Installer
      shell: pwsh
      run: |
        Write-Host "Creating MSI installer from app-image..."

        # Version loaded from VERSION file
        $version = "${{ steps.get-version.outputs.HDFVIEW_VERSION }}"

        # Use jpackage to create MSI from app-image
        jpackage `
          --type msi `
          --app-image HDFView `
          --name HDFView `
          --app-version $version `
          --icon package_files\hdfview.ico `
          --win-dir-chooser `
          --win-per-user-install `
          --win-menu `
          --win-menu-group "The HDF Group" `
          --file-associations package_files\HDFViewHDF.properties `
          --file-associations package_files\HDFViewH4.properties `
          --file-associations package_files\HDFViewHDF4.properties `
          --file-associations package_files\HDFViewH5.properties `
          --file-associations package_files\HDFViewHDF5.properties `
          --dest .

        Write-Host "MSI installer created successfully"
        Get-ChildItem *.msi

    - name: Debug - Check Signing Secrets
      shell: pwsh
      run: |
        Write-Host "Repository: ${{ github.repository }}"
        Write-Host "AZURE_TENANT_ID is set: ${{ env.AZURE_TENANT_ID != '' }}"
        Write-Host "AZURE_ENDPOINT is set: ${{ env.AZURE_ENDPOINT != '' }}"
        if ($env:AZURE_TENANT_ID) {
          Write-Host "✓ AZURE_TENANT_ID has value (length: $($env:AZURE_TENANT_ID.Length))"
        } else {
          Write-Host "✗ AZURE_TENANT_ID is empty or not set"
        }

    - name: Rename MSI for snapshots
      if: inputs.build_environment == 'snapshots'
      shell: pwsh
      run: |
        # For snapshots, rename MSI to include commit SHA (artifact_basename)
        $oldName = "HDFView-${{ steps.get-version.outputs.HDFVIEW_VERSION }}.msi"
        $newName = "${{ inputs.artifact_basename }}.msi"
        Write-Host "Renaming $oldName to $newName"
        Move-Item -Path $oldName -Destination $newName
        Get-ChildItem *.msi

    - name: Install Microsoft Trusted Signing
      if: github.repository == 'HDFGroup/hdfview' && env.AZURE_TENANT_ID != ''
      shell: pwsh
      run: |
        Write-Host "Installing Microsoft Trusted Signing tools..."
        Invoke-WebRequest -Uri https://dist.nuget.org/win-x86-commandline/latest/nuget.exe -OutFile .\nuget.exe
        .\nuget.exe install Microsoft.Windows.SDK.BuildTools -Version 10.0.22621.3233 -x
        .\nuget.exe install Microsoft.Trusted.Signing.Client -Version 1.0.53 -x

    - name: Create Trusted Signing credentials file
      if: github.repository == 'HDFGroup/hdfview' && env.AZURE_TENANT_ID != ''
      uses: jsdaniell/create-json@v1.2.3
      with:
        name: "credentials.json"
        json: '{"Endpoint": "${{ env.AZURE_ENDPOINT }}","CodeSigningAccountName": "${{ env.AZURE_CODE_SIGNING_NAME }}","CertificateProfileName": "${{ env.AZURE_CERT_PROFILE_NAME }}"}'

    - name: Sign MSI Installer with Microsoft Trusted Signing
      if: github.repository == 'HDFGroup/hdfview' && env.AZURE_TENANT_ID != ''
      shell: pwsh
      run: |
        Write-Host "Signing MSI installer with Microsoft Trusted Signing..."

        # Determine MSI filename (snapshot includes commit SHA, release uses version only)
        $version = "${{ steps.get-version.outputs.HDFVIEW_VERSION }}"
        if ("${{ inputs.build_environment }}" -eq "snapshots") {
          $msiFile = "${{ inputs.artifact_basename }}.msi"
        } else {
          $msiFile = "HDFView-${version}.msi"
        }

        Write-Host "Signing MSI: $msiFile"

        # Set paths
        $signtoolPath = "${{ github.workspace }}/Microsoft.Windows.SDK.BuildTools/bin/10.0.22621.0/x64/signtool.exe"
        $dllPath = "${{ github.workspace }}/Microsoft.Trusted.Signing.Client/bin/x64/Azure.CodeSigning.Dlib.dll"
        $metadataPath = "${{ github.workspace }}/credentials.json"

        # Sign using Microsoft Trusted Signing
        & $signtoolPath sign `
          /v `
          /debug `
          /fd SHA256 `
          /tr "http://timestamp.acs.microsoft.com" `
          /td SHA256 `
          /dlib $dllPath `
          /dmdf $metadataPath `
          $msiFile

        if ($LASTEXITCODE -ne 0) {
          Write-Error "Signing failed with exit code $LASTEXITCODE"
          exit $LASTEXITCODE
        }

        Write-Host "MSI installer signed successfully"

    - name: Upload Windows MSI Installer
      uses: actions/upload-artifact@v4
      with:
        name: ${{ inputs.build_environment == 'snapshots' && format('{0}-win64-msi', inputs.artifact_basename) || format('HDFView-{0}-win64-msi', steps.get-version.outputs.HDFVIEW_VERSION) }}
        path: ${{ inputs.build_environment == 'snapshots' && format('{0}.msi', inputs.artifact_basename) || format('HDFView-{0}.msi', steps.get-version.outputs.HDFVIEW_VERSION) }}
        retention-days: 5

  publish-packages:
    name: Publish Maven Packages
    runs-on: ubuntu-latest
    if: inputs.publish_to_maven_registry == true
    timeout-minutes: 30

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'temurin'

    - name: Cache Maven Dependencies
      uses: actions/cache@v4
      with:
        path: ~/.m2/repository
        key: ${{ runner.os }}-maven-publish-${{ hashFiles('**/pom.xml') }}

    - name: Install HDF Libraries
      run: |
        sudo apt-get update
        sudo apt-get install -y libhdf5-dev libhdf4-dev

        # Try to install Java packages if available (may not exist in all Ubuntu versions)
        sudo apt-get install -y libhdf5-java || echo "libhdf5-java not available, will use GitHub releases"
        sudo apt-get install -y libhdf4-java || echo "libhdf4-java not available, will use GitHub releases"

    - name: Install Java Dependencies to Maven Local Repository
      run: |
        echo "Installing Java dependencies..."

        # Install fits.jar and netcdf.jar from repository
        mvn install:install-file -Dfile=repository/lib/fits.jar \
          -DgroupId=fits -DartifactId=fits -Dversion=1.0.0 \
          -Dpackaging=jar -DgeneratePom=true

        mvn install:install-file -Dfile=repository/lib/netcdf.jar \
          -DgroupId=netcdf -DartifactId=netcdf -Dversion=1.0.0 \
          -Dpackaging=jar -DgeneratePom=true

        # Install HDF JARs - try system packages first, fallback to downloading
        # Note: libhdf4-java and libhdf5-java may not be available in all Ubuntu versions
        echo "Checking for HDF Java packages..."

        # Always download jarhdf5 from GitHub (system packages are outdated)
        echo "Downloading jarhdf5.jar from GitHub release: ${{ inputs.hdf5_version_tag }}..."

        # Determine file pattern based on whether base name is provided
        if [ -n "${{ inputs.hdf5_artifact_basename }}" ]; then
          PATTERN="${{ env.HDF5_PREFIX }}${{ inputs.hdf5_artifact_basename }}-ubuntu-2404_gcc.tar.gz"
        else
          PATTERN="*ubuntu-2404_gcc.tar.gz"
        fi
        echo "Using pattern: $PATTERN"

        mkdir -p /tmp/hdf5-download && cd /tmp/hdf5-download
          gh release download "${{ inputs.hdf5_version_tag }}" --repo HDFGroup/hdf5 --pattern "$PATTERN"
          tar -zxf hdf5-*-ubuntu-2404_gcc.tar.gz
          cd hdf5

          # Extract inner tar.gz
          HDF5_TARBALL=$(ls HDF5-*-Linux.tar.gz | head -1)
          tar -zxf "$HDF5_TARBALL" --strip-components 1

          # Find JAR in HDF_Group/HDF5/version/lib structure
          if [ -d HDF_Group/HDF5 ]; then
            VERSION_DIR=$(ls HDF_Group/HDF5 | head -1)
            JAR_FILE=$(ls HDF_Group/HDF5/$VERSION_DIR/lib/jarhdf5*.jar 2>/dev/null | head -1)
            if [ -f "$JAR_FILE" ]; then
              HDF5_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf5-\([0-9.]*\)\.jar/\1/p')
              mvn install:install-file -Dfile="$JAR_FILE" \
                -DgroupId=jarhdf5 -DartifactId=jarhdf5 -Dversion="$HDF5_VERSION" \
                -Dpackaging=jar -DgeneratePom=true
              echo "Installed jarhdf5.jar from GitHub: $JAR_FILE as version $HDF5_VERSION"
              echo "HDF5_VERSION=$HDF5_VERSION" >> $GITHUB_ENV
            fi
          fi
          cd ${{ github.workspace }}

        # Try jarhdf from system packages, fallback to GitHub download
        if [ -f /usr/share/java/jarhdf.jar ]; then
          echo "Installing jarhdf.jar from system packages"
          # Extract version from jar if possible, otherwise use default
          JAR_PATH="/usr/share/java/jarhdf.jar"
          # System jarhdf.jar typically doesn't have version in filename, check actual file
          if jar -tf "$JAR_PATH" | grep -q "MANIFEST.MF"; then
            HDF4_VERSION=$(unzip -p "$JAR_PATH" META-INF/MANIFEST.MF | grep "Implementation-Version" | cut -d' ' -f2 | tr -d '\r' || echo "4.3.1")
          else
            HDF4_VERSION="4.3.1"
          fi
          mvn install:install-file -Dfile="$JAR_PATH" \
            -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
            -Dpackaging=jar -DgeneratePom=true
          echo "Installed jarhdf.jar from system packages as version $HDF4_VERSION"
          echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
        else
          echo "System packages don't provide jarhdf.jar, downloading from GitHub release: ${{ inputs.hdf4_version_tag }}..."

          # Determine file pattern based on whether base name is provided
          if [ -n "${{ inputs.hdf4_artifact_basename }}" ]; then
            PATTERN="${{ inputs.hdf4_artifact_basename }}-ubuntu-2404_gcc.tar.gz"
          else
            PATTERN="*ubuntu-2404_gcc.tar.gz"
          fi
          echo "Using pattern: $PATTERN"

          mkdir -p /tmp/hdf4-download && cd /tmp/hdf4-download
          gh release download "${{ inputs.hdf4_version_tag }}" --repo HDFGroup/hdf4 --pattern "$PATTERN"
          tar -zxf hdf4*-ubuntu-2404_gcc.tar.gz
          cd hdf4

          # Extract inner tar.gz
          HDF4_TARBALL=$(ls HDF-*-Linux.tar.gz | head -1)
          tar -zxf "$HDF4_TARBALL" --strip-components 1

          # Find JAR in HDF_Group/HDF/version/lib structure
          if [ -d HDF_Group/HDF ]; then
            VERSION_DIR=$(ls HDF_Group/HDF | head -1)
            JAR_FILE=$(ls HDF_Group/HDF/$VERSION_DIR/lib/jarhdf-*.jar 2>/dev/null | head -1)
            if [ -f "$JAR_FILE" ]; then
              HDF4_VERSION=$(echo "$JAR_FILE" | sed -n 's/.*jarhdf-\([0-9.]*\)\.jar/\1/p')
              mvn install:install-file -Dfile="$JAR_FILE" \
                -DgroupId=jarhdf -DartifactId=jarhdf -Dversion="$HDF4_VERSION" \
                -Dpackaging=jar -DgeneratePom=true
              echo "Installed jarhdf.jar from GitHub: $JAR_FILE as version $HDF4_VERSION"
              echo "HDF4_VERSION=$HDF4_VERSION" >> $GITHUB_ENV
            fi
          fi
          cd ${{ github.workspace }}
        fi

        # Install SWTBot JARs for UI testing
        mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.swt.finder.jar \
          -DgroupId=org.eclipse.local -DartifactId=org.eclipse.swtbot.swt.finder -Dversion=4.2.1 \
          -Dpackaging=jar -DgeneratePom=true

        mvn install:install-file -Dfile=repository/lib/org.eclipse.swtbot.nebula.nattable.finder.jar \
          -DgroupId=org.eclipse.local -DartifactId=org.eclipse.swtbot.nebula.nattable.finder -Dversion=4.2.1 \
          -Dpackaging=jar -DgeneratePom=true

        echo "All Java dependencies installed successfully"
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up build.properties
      run: |
        cat > build.properties << EOF
        hdf5.lib.dir=/usr/lib/x86_64-linux-gnu
        hdf5.plugin.dir=/usr/lib/x86_64-linux-gnu/lib/plugin
        hdf.lib.dir=/usr/lib/x86_64-linux-gnu
        platform.hdf.lib=/usr/lib/x86_64-linux-gnu
        ci.build=true
        release.build=true
        EOF

    - name: Configure Maven Settings
      run: |
        mkdir -p ~/.m2
        cat > ~/.m2/settings.xml << EOF
        <settings>
          <servers>
            <server>
              <id>github</id>
              <username>\${env.GITHUB_ACTOR}</username>
              <password>\${env.GITHUB_TOKEN}</password>
            </server>
          </servers>
        </settings>
        EOF

    - name: Publish to GitHub Packages
      run: |
        mvn deploy -B \
          -pl object,hdfview \
          -DskipTests \
          -Ddependency-check.skip=true \
          -Dmaven.javadoc.skip=false \
          -Dmaven.source.skip=false \
          -Dhdf5.version="$HDF5_VERSION" \
          -Dhdf.version="$HDF4_VERSION" \
          -DaltDeploymentRepository=github::default::https://maven.pkg.github.com/${{ github.repository }}
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
